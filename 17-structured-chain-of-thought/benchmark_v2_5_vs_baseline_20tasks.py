#!/usr/bin/env python3
"""
V2.5 vs Baseline å¯¹æ¯”æµ‹è¯• - 20é¢˜å®Œæ•´è¯„ä¼°

æµ‹è¯•é›†æ„æˆ:
- 10é¢˜ GSM8K (5 ç®€å• + 5 ä¸­ç­‰)
- 10é¢˜ æ‰‹å·¥è®¾è®¡ (3 é€»è¾‘ + 4 æ˜“æ··æ·† + 3 å¸¸è¯†)

ç›®æ ‡: é‡åŒ–è¯æ˜ V2.5 åœ¨å¤æ‚æ¨ç†å’Œé€»è¾‘ä¸€è‡´æ€§ä¸Šæ˜¾è‘—ä¼˜äº Baseline
"""

import os
import json
import re
import time
import signal
from typing import List, Dict
from dotenv import load_dotenv
from langchain_ollama import ChatOllama
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from deepseek_r1_traces_v2 import DeepSeekR1AgentV2

# è¶…æ—¶å¼‚å¸¸
class TimeoutException(Exception):
    pass

def timeout_handler(signum, frame):
    raise TimeoutException("æ‰§è¡Œè¶…æ—¶")

# åŠ è½½ç¯å¢ƒé…ç½®
load_dotenv(override=True)

class BenchmarkRunner20Tasks:
    def __init__(self):
        use_backend = os.getenv("USE_BACKEND", "ollama")

        if use_backend == "deepseek_api":
            # DeepSeek API é…ç½®
            api_key = os.getenv("DEEPSEEK_API_KEY")
            base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1")
            self.model_name = os.getenv("DEEPSEEK_MODEL", "deepseek-reasoner")

            print(f"Test Model: {self.model_name} (DeepSeek API)")
            print(f"Judge Model: {self.model_name} (DeepSeek API)")

            # 1. Baseline LLM
            self.baseline_llm = ChatOpenAI(
                model=self.model_name,
                api_key=api_key,
                base_url=base_url,
                temperature=0
            )

            # 2. V2.5 Agent
            self.agent_v2_5 = DeepSeekR1AgentV2(
                model=self.model_name,
                enable_tools=True,
                enable_loop_detection=True,
                enable_hallucination_detection=False
            )

            # 3. Judge LLM
            self.judge_llm = ChatOpenAI(
                model=self.model_name,
                api_key=api_key,
                base_url=base_url,
                temperature=0
            )
        else:
            # Ollama æœ¬åœ°é…ç½®
            self.model_name = os.getenv("OLLAMA_MODEL", "deepseek-r1:32b")
            self.judge_model_name = os.getenv("JUDGE_MODEL", self.model_name)
            self.base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")

            print(f"Test Model: {self.model_name} (Ollama)")
            print(f"Judge Model: {self.judge_model_name} (Ollama)")

            # 1. Baseline LLM (æ™®é€šç›´æ¥å›ç­”)
            self.baseline_llm = ChatOllama(
                model=self.model_name,
                base_url=self.base_url,
                temperature=0
            )

            # 2. V2.5 Agent (ç»“æ„åŒ–4é˜¶æ®µæ¨ç†)
            self.agent_v2_5 = DeepSeekR1AgentV2(
                model=self.model_name,
                enable_tools=True,
                enable_loop_detection=True,
                enable_hallucination_detection=False
            )

            # 3. Judge LLM
            self.judge_llm = ChatOllama(
                model=self.judge_model_name,
                base_url=self.base_url,
                temperature=0
            )

    def load_gsm8k_data(self, limit=10) -> List[Dict]:
        """åŠ è½½ GSM8K æµ‹è¯•æ•°æ®"""
        file_path = os.path.join(os.path.dirname(__file__),
                               "../18-dsa-compression-experiment/benchmarks/data/reasoning/gsm8k_hf.json")

        if not os.path.exists(file_path):
            print(f"Warning: GSM8K file not found at {file_path}")
            return []

        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        tasks = []
        for item in data[:limit]:
            history = item.get('history', [])
            if not history:
                continue

            question = history[0]['content']
            question = question.replace("Please solve this math problem: ", "")
            gold_answer = history[1]['content']

            tasks.append({
                "id": item['name'],
                "question": question,
                "gold_answer": gold_answer,
                "category": "gsm8k_simple" if tasks.__len__() < 5 else "gsm8k_medium"
            })

        print(f"Loaded {len(tasks)} tasks from GSM8K.")
        return tasks

    def get_hand_crafted_tasks(self) -> List[Dict]:
        """æ‰‹å·¥è®¾è®¡çš„10é“æµ‹è¯•é¢˜"""
        tasks = []

        # === 1. é€»è¾‘è°œé¢˜ (3é¢˜) ===
        tasks.append({
            "id": "Logic_Knights_Knaves",
            "category": "logic_puzzle",
            "question": "Three people (A, B, C) are either Knights (always tell truth) or Knaves (always lie). A says: 'B is a knave'. B says: 'A and C are the same type'. C says: 'I am a Knight'. Determine who is who.",
            "gold_answer": "A is a Knight, B is a Knave, C is a Knave."
        })

        tasks.append({
            "id": "Logic_Truth_Teller",
            "category": "logic_puzzle",
            "question": "In a room, there are two people. One always tells the truth, one always lies. The first person says: 'We are both liars.' What is each person?",
            "gold_answer": "The first person is a liar, the second person is a truth-teller. The first person's statement ('We are both liars') must be false because if they were both liars, the statement would be true (a contradiction). So the first is a liar, and thus the second must be a truth-teller."
        })

        tasks.append({
            "id": "Logic_Hats",
            "category": "logic_puzzle",
            "question": "Three people wearing hats (red or blue). Each can see others' hats but not their own. First person says 'I don't know my color'. Second says 'I don't know either'. Third says 'I know my color is blue'. What are the hat colors?",
            "gold_answer": "First: Red, Second: Red, Third: Blue. If the third person can deduce their color after hearing the first two don't know, it must be because the first two are wearing the same color (red), so the third knows they must be wearing the other color (blue)."
        })

        # === 2. æ˜“æ··æ·†/æ˜“è¯¯å¯¼é¢˜ (4é¢˜) ===
        tasks.append({
            "id": "Confusing_Feathers",
            "category": "misleading",
            "question": "Which is heavier: a pound of bricks or a pound of feathers?",
            "gold_answer": "They weigh the same. Both are one pound."
        })

        tasks.append({
            "id": "Confusing_Robe_Fiber",
            "category": "misleading",
            "question": "A robe takes 2 bolts of blue fiber and half that much white fiber. How many bolts in total does it take?",
            "gold_answer": "3 bolts total. Blue: 2 bolts, White: 1 bolt (half of 2), Total: 2 + 1 = 3."
        })

        tasks.append({
            "id": "Confusing_House_Flip",
            "category": "misleading",
            "question": "Josh decides to try flipping a house. He buys a house for $80,000 and then puts in $50,000 in repairs. This increased the value of the house by 150%. How much profit did he make?",
            "gold_answer": "$70,000 profit. Cost: $80k + $50k = $130k. Increased value BY 150% means: new value = $80k Ã— 2.5 = $200k. Profit: $200k - $130k = $70k."
        })

        tasks.append({
            "id": "Confusing_Percentage",
            "category": "misleading",
            "question": "A store has a shirt that costs $40. They increase the price by 50%, then decrease it by 50%. What is the final price?",
            "gold_answer": "$30. First increase: $40 Ã— 1.5 = $60. Then decrease: $60 Ã— 0.5 = $30. (Not back to $40 because percentages are based on different bases!)"
        })

        # === 3. å¸¸è¯†æ¨ç†é¢˜ (3é¢˜) ===
        tasks.append({
            "id": "Common_Sense_Age",
            "category": "common_sense",
            "question": "If Sally is 15 years old and her brother is half her age, how old will her brother be when Sally is 30?",
            "gold_answer": "27.5 years old. When Sally is 15, her brother is 7.5. Age difference: 7.5 years. When Sally is 30, her brother is 30 - 7.5 = 22.5. Actually, if 'half her age' means 15/2 = 7.5, difference is 7.5. So when Sally is 30, brother is 22.5. Or if it means brother is currently 7.5, then when Sally is 30 (15 years later), brother is 7.5 + 15 = 22.5."
        })

        tasks.append({
            "id": "Common_Sense_Clock",
            "category": "common_sense",
            "question": "A clock shows 3:15. What is the angle between the hour hand and the minute hand?",
            "gold_answer": "7.5 degrees. At 3:15, minute hand is at 3 (90Â° from 12). Hour hand is 1/4 of the way between 3 and 4. Each hour = 30Â°, 15 min = 30Â°/4 = 7.5Â°. Hour hand is at 90Â° + 7.5Â° = 97.5Â°. Angle = 97.5Â° - 90Â° = 7.5Â°."
        })

        tasks.append({
            "id": "Common_Sense_Speed",
            "category": "common_sense",
            "question": "A car travels 60 miles in 1 hour on the highway, then 30 miles in 1 hour in the city. What is the average speed for the entire trip?",
            "gold_answer": "45 mph. Total distance: 60 + 30 = 90 miles. Total time: 1 + 1 = 2 hours. Average speed: 90 / 2 = 45 mph."
        })

        return tasks

    def clean_think_tags(self, text: str) -> str:
        """æ¸…ç† <think> æ ‡ç­¾"""
        return re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()

    def evaluate_correctness(self, question: str, gold_answer: str, candidate_answer: str, category: str) -> bool:
        """ä½¿ç”¨ LLM è£åˆ¤åˆ¤æ–­ç­”æ¡ˆæ˜¯å¦æ­£ç¡®"""
        candidate_answer = self.clean_think_tags(candidate_answer)
        gold_answer = self.clean_think_tags(gold_answer)

        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ•°å­¦å’Œé€»è¾‘é˜…å·è€å¸ˆã€‚è¯·åˆ¤æ–­è€ƒç”Ÿçš„ç­”æ¡ˆæ˜¯å¦æ­£ç¡®ã€‚

ã€é¢˜ç›®ã€‘
{question}

ã€æ ‡å‡†ç­”æ¡ˆã€‘
{gold_answer}

ã€è€ƒç”Ÿç­”æ¡ˆã€‘
{candidate_answer}

è¯·æ³¨æ„ï¼š
1. åªè¦æœ€ç»ˆç»“è®ºæˆ–æ•°å€¼ç»“æœæ­£ç¡®ï¼Œå³ä½¿è¿‡ç¨‹ç•¥æœ‰ä¸åŒä¹Ÿç®—å¯¹ã€‚
2. å¦‚æœæ ‡å‡†ç­”æ¡ˆåŒ…å« "#### X"ï¼Œåˆ™ X æ˜¯æœ€ç»ˆæ•°å€¼ã€‚
3. å¯¹äºé€»è¾‘é¢˜ï¼ˆå¦‚Knights/Knavesï¼‰ï¼Œè¯·æ£€æŸ¥æœ€ç»ˆçš„è§’è‰²åˆ†é…æ˜¯å¦ä¸€è‡´ã€‚
4. è¯·å¿½ç•¥æ ¼å¼å·®å¼‚ã€‚
5. å¯¹äºä¸­è‹±æ–‡æ··åˆï¼Œ"éª‘å£«"=Knight, "å°äºº"=Knave

è¯·åªè¾“å‡º "CORRECT" æˆ– "INCORRECT"ã€‚
        """

        try:
            response = self.judge_llm.invoke(prompt).content.strip()

            if "CORRECT" in response.upper() and "INCORRECT" not in response.upper():
                return True

            # Fallback: ç®€å•çš„æ•°å€¼åŒ¹é…
            cand_nums = re.findall(r'\d+\.?\d*', candidate_answer)
            gold_nums = re.findall(r'\d+\.?\d*', gold_answer)

            if "####" in gold_answer:
                gold_val = gold_answer.split("####")[-1].strip()
                gold_nums = re.findall(r'\d+\.?\d*', gold_val)

            if gold_nums and cand_nums:
                if abs(float(cand_nums[-1]) - float(gold_nums[-1])) < 1e-6:
                    return True

            return False
        except Exception as e:
            print(f"Judge Error: {e}")
            return False

    def run_benchmark(self):
        """è¿è¡Œå®Œæ•´çš„ 20 é¢˜ benchmark"""
        # 1. åŠ è½½æµ‹è¯•æ•°æ®
        gsm8k_tasks = self.load_gsm8k_data(limit=10)
        hand_tasks = self.get_hand_crafted_tasks()
        all_tasks = gsm8k_tasks + hand_tasks

        if len(all_tasks) < 20:
            print(f"Warning: Only loaded {len(all_tasks)} tasks (expected 20)")

        print(f"\n{'='*60}")
        print(f"å¼€å§‹ V2.5 vs Baseline å¯¹æ¯”æµ‹è¯• (20é¢˜)")
        print(f"{'='*60}\n")

        results = {
            "baseline": {
                "correct": 0,
                "total": 0,
                "times": [],
                "by_category": {}
            },
            "v2_5": {
                "correct": 0,
                "total": 0,
                "times": [],
                "by_category": {}
            }
        }

        # 2. è¿è¡Œæ¯ä¸ªæµ‹è¯•
        for idx, task in enumerate(all_tasks, 1):
            category = task.get('category', 'unknown')
            print(f"\n{'='*60}")
            print(f"Task {idx}/20: {task['id']} [{category}]")
            print(f"é—®é¢˜: {task['question'][:80]}...")
            print(f"{'='*60}")

            # ========== Baseline ==========
            print(f"\n  [1/2] Running Baseline (Direct Answer)...", end=" ", flush=True)
            start_time = time.time()
            baseline_correct = False
            baseline_time = 0

            # è®¾ç½®5åˆ†é’Ÿè¶…æ—¶
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(300)  # 5åˆ†é’Ÿ = 300ç§’

            try:
                baseline_response = self.baseline_llm.invoke([HumanMessage(content=task['question'])])
                baseline_answer = baseline_response.content
                baseline_time = time.time() - start_time
                signal.alarm(0)  # å–æ¶ˆè¶…æ—¶

                baseline_correct = self.evaluate_correctness(
                    task['question'],
                    task['gold_answer'],
                    baseline_answer,
                    category
                )
                results["baseline"]["total"] += 1
                results["baseline"]["times"].append(baseline_time)
                if baseline_correct:
                    results["baseline"]["correct"] += 1

                # æŒ‰ç±»åˆ«ç»Ÿè®¡
                if category not in results["baseline"]["by_category"]:
                    results["baseline"]["by_category"][category] = {"correct": 0, "total": 0}
                results["baseline"]["by_category"][category]["total"] += 1
                if baseline_correct:
                    results["baseline"]["by_category"][category]["correct"] += 1

                print(f"Time: {baseline_time:.2f}s | Result: {'âœ…' if baseline_correct else 'âŒ'}")
            except TimeoutException:
                signal.alarm(0)
                baseline_time = time.time() - start_time
                print(f"â±ï¸ TIMEOUT ({baseline_time:.0f}s) | Result: âŒ")
                results["baseline"]["total"] += 1
                results["baseline"]["times"].append(baseline_time)
                if category not in results["baseline"]["by_category"]:
                    results["baseline"]["by_category"][category] = {"correct": 0, "total": 0}
                results["baseline"]["by_category"][category]["total"] += 1
            except Exception as e:
                signal.alarm(0)
                print(f"Error: {e}")
                results["baseline"]["total"] += 1

            # ========== V2.5 Structured 4-Stage ==========
            print(f"  [2/2] Running V2.5 (Structured 4-Stage)...", end=" ", flush=True)
            start_time = time.time()
            v2_5_correct = False
            v2_5_time = 0

            # è®¾ç½®5åˆ†é’Ÿè¶…æ—¶
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(300)  # 5åˆ†é’Ÿ = 300ç§’

            try:
                # å¼ºåˆ¶ä½¿ç”¨ structured_4stage æ¨¡å¼
                v2_5_answer = self.agent_v2_5.run(
                    task['question'],
                    mode="structured_4stage",
                    verbose=False
                )
                v2_5_time = time.time() - start_time
                signal.alarm(0)  # å–æ¶ˆè¶…æ—¶

                v2_5_correct = self.evaluate_correctness(
                    task['question'],
                    task['gold_answer'],
                    v2_5_answer,
                    category
                )
                results["v2_5"]["total"] += 1
                results["v2_5"]["times"].append(v2_5_time)
                if v2_5_correct:
                    results["v2_5"]["correct"] += 1

                # æŒ‰ç±»åˆ«ç»Ÿè®¡
                if category not in results["v2_5"]["by_category"]:
                    results["v2_5"]["by_category"][category] = {"correct": 0, "total": 0}
                results["v2_5"]["by_category"][category]["total"] += 1
                if v2_5_correct:
                    results["v2_5"]["by_category"][category]["correct"] += 1

                print(f"Time: {v2_5_time:.2f}s | Result: {'âœ…' if v2_5_correct else 'âŒ'}")
            except TimeoutException:
                signal.alarm(0)
                v2_5_time = time.time() - start_time
                print(f"â±ï¸ TIMEOUT ({v2_5_time:.0f}s) | Result: âŒ")
                results["v2_5"]["total"] += 1
                results["v2_5"]["times"].append(v2_5_time)
                if category not in results["v2_5"]["by_category"]:
                    results["v2_5"]["by_category"][category] = {"correct": 0, "total": 0}
                results["v2_5"]["by_category"][category]["total"] += 1
            except Exception as e:
                signal.alarm(0)
                print(f"Error: {e}")
                results["v2_5"]["total"] += 1

        # 3. è¾“å‡ºæœ€ç»ˆç»“æœ
        self.generate_report(results)

    def generate_report(self, results: Dict):
        """ç”Ÿæˆè¯¦ç»†å¯¹æ¯”æŠ¥å‘Š"""
        print(f"\n\n{'='*60}")
        print("V2.5 vs Baseline å¯¹æ¯”æµ‹è¯•ç»“æœï¼ˆ20é¢˜ï¼‰")
        print(f"{'='*60}\n")

        # 1. æ€»ä½“å‡†ç¡®ç‡å¯¹æ¯”
        baseline_acc = (results["baseline"]["correct"] / results["baseline"]["total"] * 100) if results["baseline"]["total"] > 0 else 0
        v2_5_acc = (results["v2_5"]["correct"] / results["v2_5"]["total"] * 100) if results["v2_5"]["total"] > 0 else 0

        print("ã€å‡†ç¡®ç‡å¯¹æ¯”ã€‘")
        print(f"Baseline:    {baseline_acc:.1f}% ({results['baseline']['correct']}/{results['baseline']['total']})")
        print(f"V2.5:        {v2_5_acc:.1f}% ({results['v2_5']['correct']}/{results['v2_5']['total']})")
        print(f"æå‡å¹…åº¦:    {v2_5_acc - baseline_acc:+.1f}%\n")

        # 2. åˆ†ç±»åˆ«è¡¨ç°
        print("ã€åˆ†ç±»åˆ«è¡¨ç°ã€‘")
        print(f"{'ç±»åˆ«':<20} {'Baseline':<15} {'V2.5':<15} {'è¯´æ˜'}")
        print("-" * 70)

        all_categories = set(list(results["baseline"]["by_category"].keys()) + list(results["v2_5"]["by_category"].keys()))
        for cat in sorted(all_categories):
            baseline_cat = results["baseline"]["by_category"].get(cat, {"correct": 0, "total": 0})
            v2_5_cat = results["v2_5"]["by_category"].get(cat, {"correct": 0, "total": 0})

            baseline_pct = (baseline_cat["correct"] / baseline_cat["total"] * 100) if baseline_cat["total"] > 0 else 0
            v2_5_pct = (v2_5_cat["correct"] / v2_5_cat["total"] * 100) if v2_5_cat["total"] > 0 else 0

            desc = ""
            if cat == "gsm8k_simple":
                desc = "(å¯¹ç…§ç»„)"
            elif cat == "logic_puzzle":
                desc = "(æ ¸å¿ƒéªŒè¯)"
            elif cat == "misleading":
                desc = "(å¹»è§‰é˜²æŠ¤)"

            print(f"{cat:<20} {baseline_pct:>5.0f}% ({baseline_cat['correct']}/{baseline_cat['total']})      {v2_5_pct:>5.0f}% ({v2_5_cat['correct']}/{v2_5_cat['total']})      {desc}")

        # 3. æ¨ç†æ—¶é—´
        baseline_avg_time = sum(results["baseline"]["times"]) / len(results["baseline"]["times"]) if results["baseline"]["times"] else 0
        v2_5_avg_time = sum(results["v2_5"]["times"]) / len(results["v2_5"]["times"]) if results["v2_5"]["times"] else 0

        print(f"\nã€æ¨ç†æ—¶é—´ã€‘")
        print(f"Baseline: å¹³å‡ {baseline_avg_time:.1f}s/é¢˜")
        print(f"V2.5:     å¹³å‡ {v2_5_avg_time:.1f}s/é¢˜")
        if baseline_avg_time > 0:
            print(f"æ—¶é—´æ¯”:    {v2_5_avg_time/baseline_avg_time:.1f}x")

        # 4. ç»“è®º
        print(f"\nã€ç»“è®ºã€‘")
        if v2_5_acc > baseline_acc:
            print(f"âœ… V2.5 åœ¨å‡†ç¡®ç‡ä¸Šæ˜¾è‘—ä¼˜äº Baseline (+{v2_5_acc - baseline_acc:.1f}%)")
        elif v2_5_acc == baseline_acc:
            print(f"âš–ï¸ V2.5 ä¸ Baseline è¡¨ç°ç›¸å½“")
        else:
            print(f"âš ï¸ V2.5 è¡¨ç°ä¸å¦‚ Baseline (å¯èƒ½éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–)")

        if v2_5_avg_time > baseline_avg_time * 2:
            print(f"âš ï¸ ä»£ä»·æ˜¯æ¨ç†æ—¶é—´å¢åŠ çº¦ {v2_5_avg_time/baseline_avg_time:.1f} å€")

        print(f"ğŸ’¡ å»ºè®®: ç®€å•é—®é¢˜ç”¨ single_thinkï¼Œå¤æ‚é—®é¢˜ç”¨ structured_4stage")
        print(f"{'='*60}\n")


if __name__ == "__main__":
    runner = BenchmarkRunner20Tasks()
    runner.run_benchmark()
