"""
DeepSeek-R1 Agent V2 - Improved Chain-of-Thought Reasoning

This is a complete rewrite of the structured thinking chain agent,
designed to mimic real LLM thinking patterns (like DeepSeek-R1, OpenAI o1)
using <think> and <answer> tags.

Key Improvements over V1:
1. Natural single-pass thinking instead of forced 4-stage pipeline
2. <think> and <answer> tags for structured reasoning
3. Tool integration (calculator) for mathematical validation
4. Loop detection to prevent infinite repetition
5. Hallucination detection to avoid introducing non-existent information
6. Larger model (32b) for better reasoning capability
"""

import os
import signal
import functools
from typing import Literal, Dict, Any, Optional
from dotenv import load_dotenv

from langchain_ollama import ChatOllama
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser


# è¶…æ—¶å¼‚å¸¸ç±»
class StageTimeoutError(Exception):
    """Stage execution timeout exception"""
    pass


# è¶…æ—¶è£…é¥°å™¨
def with_timeout(seconds=120):
    """
    ä¸º Stage æ–¹æ³•æ·»åŠ è¶…æ—¶ä¿æŠ¤

    Args:
        seconds: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰,é»˜è®¤ 120 ç§’ï¼ˆ2 åˆ†é’Ÿï¼‰
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            def timeout_handler(signum, frame):
                raise StageTimeoutError(f"{func.__name__} exceeded {seconds} seconds")

            # è®¾ç½®è¶…æ—¶ä¿¡å·
            old_handler = signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(seconds)

            try:
                result = func(*args, **kwargs)
                signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
                return result
            except StageTimeoutError:
                signal.alarm(0)
                # è¶…æ—¶æ—¶è¿”å›ç®€åŒ–çš„é»˜è®¤å“åº”
                stage_name = func.__name__.replace("_stage", "Stage ").replace("_", " ")
                print(f"\nâ±ï¸ {stage_name} è¶…æ—¶ ({seconds}s)ï¼Œä½¿ç”¨ç®€åŒ–å“åº”")
                return "<answer>ç»§ç»­å¤„ç†ï¼ˆè¶…æ—¶ç®€åŒ–ï¼‰</answer>"
            finally:
                signal.signal(signal.SIGALRM, old_handler)

        return wrapper
    return decorator

# Memory æ”¯æŒï¼ˆå…¼å®¹æ–°æ—§ç‰ˆæœ¬ï¼‰
try:
    from langchain.memory import ConversationBufferMemory
except ImportError:
    # å®Œå…¨ç‹¬ç«‹çš„ Memory å®ç°ï¼Œä¸ä¾èµ–ä»»ä½• langchain åŸºç±»
    class ConversationBufferMemory:
        def __init__(self, return_messages=True, memory_key="chat_history"):
            self.messages = []
            self.return_messages = return_messages
            self.memory_key = memory_key

        def load_memory_variables(self, inputs):
            return {self.memory_key: self.messages}

        def save_context(self, inputs, outputs):
            self.messages.append({"role": "user", "content": str(inputs)})
            self.messages.append({"role": "assistant", "content": str(outputs)})

        def clear(self):
            self.messages = []

# å·¥å…·æ”¯æŒï¼ˆå¯é€‰ï¼‰
try:
    from langchain.agents import AgentExecutor, create_react_agent
    AGENTS_AVAILABLE = True
except ImportError:
    AGENTS_AVAILABLE = False
    AgentExecutor = None
    create_react_agent = None

from prompts import (
    GATE_PROMPT,
    DIRECT_PROMPT,
    SINGLE_THINK_PROMPT,
    TOOL_ENHANCED_PROMPT,
    MULTI_REFLECT_PROMPTS,
    # V2.5: Structured 4-Stage Prompts
    STAGE1_PROBLEM_DEF_V2_5,
    STAGE2_BLOOM_V2_5,
    STAGE3_VALIDATION_V2_5,
    STAGE4_FINAL_V2_5
)
from tools import ToolRegistry
from validators import LoopBreaker, HallucinationDetector
from parsers import ThinkTagParser

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


def get_llm(model: Optional[str] = None, temperature: float = 0.2):
    """
    åˆ›å»ºå¹¶é…ç½® LLM å®ä¾‹ (æ”¯æŒ DeepSeek API æˆ– Ollama)

    Args:
        model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
        temperature: æ¸©åº¦å‚æ•°ï¼Œè¶Šä½è¶Šç¡®å®šæ€§

    Returns:
        Chat LLM å®ä¾‹
    """
    use_backend = os.getenv("USE_BACKEND", "ollama")

    if use_backend == "deepseek_api":
        # ä½¿ç”¨ DeepSeek å®˜æ–¹ API
        api_key = os.getenv("DEEPSEEK_API_KEY")
        base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1")
        model_name = model or os.getenv("DEEPSEEK_MODEL", "deepseek-reasoner")

        if not api_key:
            raise ValueError("ä½¿ç”¨ DeepSeek API éœ€è¦è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")

        print(f"æ­£åœ¨ä½¿ç”¨ DeepSeek API: {model_name} (URL: {base_url})")

        return ChatOpenAI(
            model=model_name,
            api_key=api_key,
            base_url=base_url,
            temperature=temperature
        )
    else:
        # ä½¿ç”¨æœ¬åœ° Ollama
        model_name = model or os.getenv("OLLAMA_MODEL", "deepseek-r1:32b")
        base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")

        print(f"æ­£åœ¨ä½¿ç”¨ Ollama æœ¬åœ°æ¨¡å‹: {model_name} (URL: {base_url})")

        return ChatOllama(
            model=model_name,
            base_url=base_url,
            temperature=temperature
        )


class DeepSeekR1AgentV2:
    """
    æ··åˆå¼æ€ç»´é“¾ Agent (V2)

    æ ¸å¿ƒæ”¹è¿›ï¼š
    1. ä½¿ç”¨ deepseek-r1:32b å¤§æ¨¡å‹
    2. æ¨¡ä»¿çœŸå® LLM çš„ <think> æ ‡ç­¾æ¨¡å¼
    3. é›†æˆå·¥å…·è°ƒç”¨ï¼ˆè®¡ç®—å™¨/Pythonï¼‰
    4. å¾ªç¯å’Œå¹»è§‰æ£€æµ‹
    5. ä¸‰ç§æ¨ç†æ¨¡å¼è‡ªé€‚åº”åˆ‡æ¢
    """

    MODES = {
        "direct": "ç›´æ¥å›ç­”ï¼ˆç®€å•é—®é¢˜ï¼‰",
        "single_think": "å•æ¬¡æ·±åº¦æ€è€ƒï¼ˆå¿«é€Ÿæ¨ç†ï¼‰",
        "structured_4stage": "ç»“æ„åŒ–4é˜¶æ®µï¼ˆå¤æ‚æ¨ç†ï¼ŒV2.5æ–°å¢ï¼‰",
        "multi_reflect": "å¤šè½®åæ€ï¼ˆæå¤æ‚åœºæ™¯ï¼‰"
    }

    def __init__(
        self,
        model: str = "deepseek-r1:32b",
        enable_tools: bool = True,
        enable_loop_detection: bool = True,
        enable_hallucination_detection: bool = False  # é»˜è®¤å…³é—­ä»¥æé«˜é€Ÿåº¦
    ):
        """
        åˆå§‹åŒ– Agent

        Args:
            model: æ¨¡å‹åç§°
            enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·
            enable_loop_detection: æ˜¯å¦å¯ç”¨å¾ªç¯æ£€æµ‹
            enable_hallucination_detection: æ˜¯å¦å¯ç”¨å¹»è§‰æ£€æµ‹
        """
        self.llm = get_llm(model)
        self.parser = ThinkTagParser()
        self.enable_tools = enable_tools
        self.enable_loop_detection = enable_loop_detection
        self.enable_hallucination_detection = enable_hallucination_detection

        # åˆå§‹åŒ–ç»„ä»¶
        if enable_loop_detection:
            self.loop_breaker = LoopBreaker(similarity_threshold=0.85)
        if enable_hallucination_detection:
            self.hallucination_detector = HallucinationDetector(self.llm)

        # è·å–å·¥å…·
        if enable_tools:
            self.tools = ToolRegistry.get_basic_tools()
        else:
            self.tools = []

        # V2.5: åˆå§‹åŒ– Memory for structured_4stage mode
        self.memory = ConversationBufferMemory(
            return_messages=True,
            memory_key="chat_history"
        )

        # æ„å»ºæ¨ç†é“¾
        self._build_chains()

    def _build_chains(self):
        """æ„å»ºæ¨ç†é“¾"""
        # é—¨æ§é“¾
        self.gate_chain = GATE_PROMPT | self.llm | StrOutputParser()

        # ç›´æ¥å›ç­”é“¾
        self.direct_chain = DIRECT_PROMPT | self.llm | StrOutputParser()

        # å•æ¬¡æ€è€ƒé“¾ï¼ˆæ¨èï¼‰
        self.single_think_chain = SINGLE_THINK_PROMPT | self.llm | StrOutputParser()

        # å·¥å…·å¢å¼ºé“¾
        if self.enable_tools and self.tools and AGENTS_AVAILABLE:
            try:
                from langchain_core.prompts import PromptTemplate

                # åˆ›å»ºç®€å•çš„ ReAct prompt
                react_prompt = PromptTemplate.from_template(TOOL_ENHANCED_PROMPT.template)

                self.tool_agent = create_react_agent(
                    llm=self.llm,
                    tools=self.tools,
                    prompt=react_prompt
                )
                self.tool_executor = AgentExecutor(
                    agent=self.tool_agent,
                    tools=self.tools,
                    verbose=True,
                    max_iterations=5,
                    handle_parsing_errors=True
                )
            except Exception as e:
                print(f"å·¥å…·é“¾åˆå§‹åŒ–å¤±è´¥: {e}")
                self.tool_executor = None
        else:
            self.tool_executor = None

    def classify_complexity(self, user_input: str) -> Literal["direct", "single_think", "structured_4stage", "multi_reflect"]:
        """
        åˆ†ç±»ä»»åŠ¡å¤æ‚åº¦ï¼ˆV2.5 æ›´æ–°ï¼šæ”¯æŒ structured_4stageï¼‰

        Args:
            user_input: ç”¨æˆ·è¾“å…¥

        Returns:
            æ¨ç†æ¨¡å¼ï¼šdirect, single_think, structured_4stage, æˆ– multi_reflect
        """
        # ç®€å•é—®é¢˜çš„å…³é”®è¯
        simple_keywords = ["ä½ å¥½", "hello", "hi", "è°¢è°¢", "thanks", "å†è§", "bye"]
        if any(kw in user_input.lower() for kw in simple_keywords):
            return "direct"

        # V2.5: å¤æ‚é—®é¢˜æŒ‡æ ‡ â†’ structured_4stage
        complexity_indicators = [
            len(user_input) > 100,  # é—®é¢˜æè¿°è¾ƒé•¿
            user_input.count('ï¼Œ') > 3 or user_input.count(',') > 3,  # å¤šä¸ªå­å¥
            any(kw in user_input.lower() for kw in ["é¦–å…ˆ", "ç„¶å", "æ¥ç€", "æœ€å", "first", "then", "next", "finally"]),  # å¤šæ­¥éª¤
            any(kw in user_input.lower() for kw in ["è®¾è®¡", "è§„åˆ’", "åˆ†æ", "æ¯”è¾ƒ", "design", "plan", "analyze", "compare"])  # å¤æ‚ä»»åŠ¡
        ]

        if sum(complexity_indicators) >= 2:
            return "structured_4stage"

        # æ•°å­¦/é€»è¾‘é—®é¢˜ â†’ single_thinkï¼ˆæ›´å¿«ï¼‰
        math_keywords = ["å¤šå°‘", "how many", "è®¡ç®—", "solve", "ç®—", "å‡ ", "total"]
        if any(kw in user_input.lower() for kw in math_keywords):
            return "single_think"

        # é»˜è®¤ä½¿ç”¨ single_thinkï¼ˆæœ€ç¨³å®šï¼‰
        return "single_think"

    def run(self, user_input: str, mode: Optional[str] = None, verbose: bool = True) -> str:
        """
        æ‰§è¡Œæ¨ç†

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            mode: å¼ºåˆ¶æŒ‡å®šæ¨ç†æ¨¡å¼ï¼ˆå¯é€‰ï¼‰
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            æœ€ç»ˆç­”æ¡ˆ
        """
        if verbose:
            print(f"\n{'='*60}")
            print(f"è¾“å…¥: {user_input}")
            # å…¼å®¹ ChatOllama (ä½¿ç”¨ .model) å’Œ ChatOpenAI (ä½¿ç”¨ .model_name)
            model_name = getattr(self.llm, 'model', None) or getattr(self.llm, 'model_name', 'unknown')
            print(f"æ¨¡å‹: {model_name}")

        # 1. åˆ†ç±»æˆ–ä½¿ç”¨æŒ‡å®šæ¨¡å¼
        if mode is None:
            mode = self.classify_complexity(user_input)

        if verbose:
            print(f"æ¨ç†æ¨¡å¼: {self.MODES.get(mode, mode)}")
            print(f"{'='*60}\n")

        # 2. æ‰§è¡Œå¯¹åº”æ¨¡å¼
        try:
            if mode == "direct":
                output = self._direct_answer(user_input)
            elif mode == "single_think":
                output = self._single_think(user_input, verbose=verbose)
            elif mode == "structured_4stage":
                # V2.5: æ–°å¢çš„ç»“æ„åŒ–4é˜¶æ®µæ¨¡å¼
                output = self._structured_4stage(user_input, verbose=verbose)
            elif mode == "multi_reflect":
                output = self._multi_reflect(user_input, verbose=verbose)
            else:
                # é»˜è®¤ä½¿ç”¨ single_think
                output = self._single_think(user_input, verbose=verbose)

            # 3. è§£æè¾“å‡º
            parsed = self.parser.parse(output)

            if verbose:
                print(f"\n{'='*60}")
                if parsed['think']:
                    print(f"æ€è€ƒè¿‡ç¨‹:\n{parsed['think'][:500]}...")
                print(f"\næœ€ç»ˆç­”æ¡ˆ:\n{parsed['answer']}")
                print(f"{'='*60}\n")

            return parsed['answer']

        except Exception as e:
            error_msg = f"æ‰§è¡Œå¤±è´¥: {str(e)}"
            print(f"\né”™è¯¯: {error_msg}")
            return error_msg

    def _direct_answer(self, user_input: str) -> str:
        """ç›´æ¥å›ç­”æ¨¡å¼ï¼ˆç®€å•é—®é¢˜ï¼‰"""
        return self.direct_chain.invoke({"input": user_input})

    def _single_think(self, user_input: str, verbose: bool = True) -> str:
        """å•æ¬¡æ·±åº¦æ€è€ƒæ¨¡å¼ï¼ˆæ¨èï¼‰"""
        # å…ˆå°è¯•çº¯ LLM
        output = self.single_think_chain.invoke({"input": user_input})

        # æ£€æŸ¥å¾ªç¯
        if self.enable_loop_detection:
            is_loop, suggestion = self.loop_breaker.check_and_break(output)
            if is_loop:
                if verbose:
                    print(f"âš ï¸ {suggestion}")

                # å¦‚æœæ£€æµ‹åˆ°å¾ªç¯ä¸”å·¥å…·å¯ç”¨ï¼Œä½¿ç”¨å·¥å…·é‡æ–°å°è¯•
                if self.tool_executor:
                    if verbose:
                        print("æ­£åœ¨ä½¿ç”¨å·¥å…·é‡æ–°è®¡ç®—...")
                    try:
                        result = self.tool_executor.invoke({"input": user_input})
                        output = result.get("output", output)
                    except Exception as e:
                        if verbose:
                            print(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")

        # æ£€æŸ¥å¹»è§‰
        if self.enable_hallucination_detection:
            parsed = self.parser.parse(output)
            if parsed['think']:
                validation = self.hallucination_detector.validate(user_input, parsed['think'])
                if not validation['is_valid'] and verbose:
                    print(f"âš ï¸ æ£€æµ‹åˆ°å¯èƒ½çš„å¹»è§‰:")
                    for issue in validation['issues']:
                        print(f"  - {issue}")

        return output

    def _multi_reflect(self, user_input: str, verbose: bool = True) -> str:
        """å¤šè½®åæ€æ¨¡å¼ï¼ˆå¤æ‚åœºæ™¯ï¼‰"""
        # Think â†’ Verify â†’ Refine â†’ Answer
        if verbose:
            print("ç¬¬1æ­¥ï¼šåˆå§‹æ€è€ƒ...")
        think_output = self.single_think_chain.invoke({"input": user_input})

        # Verify step
        if verbose:
            print("ç¬¬2æ­¥ï¼šéªŒè¯æ¨ç†...")
        verify_prompt = MULTI_REFLECT_PROMPTS["verify"]
        verification = (verify_prompt | self.llm | StrOutputParser()).invoke({
            "input": user_input,
            "previous_think": think_output
        })

        # Refine step
        if verbose:
            print("ç¬¬3æ­¥ï¼šä¿®æ­£ç­”æ¡ˆ...")
        refine_prompt = MULTI_REFLECT_PROMPTS["refine"]
        final_output = (refine_prompt | self.llm | StrOutputParser()).invoke({
            "input": user_input,
            "verification": verification
        })

        return final_output

    # ========================================================================
    # V2.5: Structured 4-Stage Reasoning Mode (ç”¨æˆ·è¦æ±‚çš„ç»“æ„åŒ–4é˜¶æ®µ)
    # ========================================================================

    def _structured_4stage(self, user_input: str, verbose: bool = True) -> str:
        """
        ç»“æ„åŒ– 4 é˜¶æ®µæ¨ç†æ¨¡å¼ (V2.5)

        æ ¸å¿ƒæ”¹è¿›ï¼š
        1. ä½¿ç”¨ Memory ç®¡ç†å„é˜¶æ®µä¸Šä¸‹æ–‡
        2. Stage 3 æ”¹ä¸º"éªŒè¯"è€Œé"é­”é¬¼ä»£è¨€äºº"
        3. å·¥å…·åœ¨ Stage 2 å¯ç”¨
        4. æ£€æµ‹å™¨åœ¨ Stage 3 é›†æˆ

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            æœ€ç»ˆç­”æ¡ˆå­—ç¬¦ä¸²
        """
        if verbose:
            print("\nğŸ”„ ä½¿ç”¨ç»“æ„åŒ– 4 é˜¶æ®µæ¨ç†æ¨¡å¼ (V2.5)")
            print("="*60)

        # åˆå§‹åŒ– memory
        self.memory.clear()
        self.memory.save_context(
            {"input": user_input},
            {"output": "å¼€å§‹ 4 é˜¶æ®µæ¨ç†"}
        )

        # Stage 1: Problem Definition
        if verbose:
            print("\nğŸ“‹ é˜¶æ®µ 1/4: é—®é¢˜å®šä¹‰")
            print("-"*60)
        stage1_output = self._stage1_problem_definition(user_input, verbose=verbose)
        self.memory.save_context(
            {"input": f"[Stage 1: Problem Definition]\n{user_input}"},
            {"output": stage1_output}
        )

        # Stage 2: Bloom (Path Exploration with Tools)
        if verbose:
            print("\nğŸŒ¸ é˜¶æ®µ 2/4: è·¯å¾„æ¢ç´¢ï¼ˆå¸¦å·¥å…·æ”¯æŒï¼‰")
            print("-"*60)
        stage2_output = self._stage2_bloom_with_tools(user_input, stage1_output, verbose=verbose)
        self.memory.save_context(
            {"input": "[Stage 2: Bloom - Path Exploration]"},
            {"output": stage2_output}
        )

        # Stage 3: Validation (NOT Devil's Advocate!)
        if verbose:
            print("\nâœ… é˜¶æ®µ 3/4: éªŒè¯ï¼ˆéé­”é¬¼ä»£è¨€äººï¼‰")
            print("-"*60)
        stage3_output = self._stage3_validation_not_devil(user_input, stage1_output, stage2_output, verbose=verbose)
        self.memory.save_context(
            {"input": "[Stage 3: Validation]"},
            {"output": stage3_output}
        )

        # Stage 4: Final Decision
        if verbose:
            print("\nğŸ¯ é˜¶æ®µ 4/4: æœ€ç»ˆå†³ç­–")
            print("-"*60)
        final_output = self._stage4_final_decision(user_input, stage3_output, verbose=verbose)

        if verbose:
            print("\n" + "="*60)
            print("âœ¨ 4 é˜¶æ®µæ¨ç†å®Œæˆ")
            print("="*60)

        return final_output

    @with_timeout(seconds=120)  # Stage 1 æœ€å¤š 2 åˆ†é’Ÿ
    def _stage1_problem_definition(self, user_input: str, verbose: bool = True) -> str:
        """
        é˜¶æ®µ 1: é—®é¢˜å®šä¹‰

        åˆ†æé—®é¢˜çš„å…³é”®ä¿¡æ¯ï¼Œæå–å·²çŸ¥æ¡ä»¶å’Œç›®æ ‡
        """
        chain = STAGE1_PROBLEM_DEF_V2_5 | self.llm | StrOutputParser()
        output = chain.invoke({"input": user_input})

        if verbose:
            parsed = self.parser.parse(output)
            if parsed['think']:
                print(f"æ€è€ƒ: {parsed['think'][:200]}...")
            print(f"å®šä¹‰: {parsed['answer'][:300]}...")

        return output

    @with_timeout(seconds=120)  # Stage 2 æœ€å¤š 2 åˆ†é’Ÿ
    def _stage2_bloom_with_tools(self, user_input: str, stage1_output: str, verbose: bool = True) -> str:
        """
        é˜¶æ®µ 2: è·¯å¾„æ¢ç´¢ï¼ˆå¸¦å·¥å…·æ”¯æŒï¼‰

        åŸºäºé—®é¢˜å®šä¹‰ï¼Œæ¢ç´¢ 2-3 ç§è§£å†³è·¯å¾„ï¼Œå¯ä½¿ç”¨ calculator å·¥å…·
        """
        # è·å–å†å²
        history = self.memory.load_memory_variables({})
        chat_history_str = self._format_chat_history(history.get("chat_history", []))

        # æ„é€ æç¤ºè¯
        prompt_text = STAGE2_BLOOM_V2_5.format(
            original_question=user_input,
            stage1_output=stage1_output,
            chat_history=chat_history_str
        )

        # å¦‚æœå·¥å…·å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨å·¥å…·
        if self.tool_executor:
            try:
                result = self.tool_executor.invoke({"input": prompt_text})
                output = result.get("output", "")
            except Exception as e:
                if verbose:
                    print(f"âš ï¸ å·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œä½¿ç”¨çº¯ LLM: {e}")
                chain = STAGE2_BLOOM_V2_5 | self.llm | StrOutputParser()
                output = chain.invoke({
                    "original_question": user_input,
                    "stage1_output": stage1_output,
                    "chat_history": chat_history_str
                })
        else:
            chain = STAGE2_BLOOM_V2_5 | self.llm | StrOutputParser()
            output = chain.invoke({
                "original_question": user_input,
                "stage1_output": stage1_output,
                "chat_history": chat_history_str
            })

        if verbose:
            parsed = self.parser.parse(output)
            if parsed['think']:
                print(f"è·¯å¾„æ¢ç´¢: {parsed['think'][:200]}...")
            print(f"æ¨è: {parsed['answer'][:300]}...")

        return output

    @with_timeout(seconds=120)  # Stage 3 æœ€å¤š 2 åˆ†é’Ÿï¼ˆå…³é”®é˜¶æ®µï¼Œå®¹æ˜“è¶…æ—¶ï¼‰
    def _stage3_validation_not_devil(self, user_input: str, stage1_output: str, stage2_output: str, verbose: bool = True) -> str:
        """
        é˜¶æ®µ 3: éªŒè¯ï¼ˆéé­”é¬¼ä»£è¨€äººï¼‰

        éªŒè¯æ¨ç†å‡†ç¡®æ€§ï¼Œä½¿ç”¨å¾ªç¯å’Œå¹»è§‰æ£€æµ‹å™¨
        å…³é”®ï¼šä»…éªŒè¯ï¼Œä¸åˆ›é€ æ–°å‡è®¾
        """
        # è·å–å†å²
        history = self.memory.load_memory_variables({})
        chat_history_str = self._format_chat_history(history.get("chat_history", []))

        chain = STAGE3_VALIDATION_V2_5 | self.llm | StrOutputParser()
        output = chain.invoke({
            "original_question": user_input,
            "stage1_output": stage1_output,
            "stage2_output": stage2_output,
            "chat_history": chat_history_str
        })

        # å¾ªç¯æ£€æµ‹
        if self.enable_loop_detection:
            is_loop, msg = self.loop_breaker.check_and_break(output)
            if is_loop and verbose:
                print(f"âš ï¸ {msg}")

        # å¹»è§‰æ£€æµ‹
        if self.enable_hallucination_detection:
            parsed = self.parser.parse(output)
            if parsed['think']:
                validation = self.hallucination_detector.validate(user_input, parsed['think'])
                if not validation['is_valid'] and verbose:
                    print(f"âš ï¸ æ£€æµ‹åˆ°å¯èƒ½çš„å¹»è§‰:")
                    for issue in validation['issues']:
                        print(f"  - {issue}")

        if verbose:
            parsed = self.parser.parse(output)
            if parsed['think']:
                print(f"éªŒè¯: {parsed['think'][:200]}...")
            print(f"ç»“æœ: {parsed['answer'][:300]}...")

        return output

    @with_timeout(seconds=120)  # Stage 4 æœ€å¤š 2 åˆ†é’Ÿ
    def _stage4_final_decision(self, user_input: str, stage3_validation: str, verbose: bool = True) -> str:
        """
        é˜¶æ®µ 4: æœ€ç»ˆå†³ç­–

        åŸºäºå®Œæ•´æ¨ç†å†å²å’ŒéªŒè¯ç»“æœï¼Œè¾“å‡ºæœ€ç»ˆç­”æ¡ˆ
        """
        # è·å–å†å²
        history = self.memory.load_memory_variables({})
        chat_history_str = self._format_chat_history(history.get("chat_history", []))

        chain = STAGE4_FINAL_V2_5 | self.llm | StrOutputParser()
        output = chain.invoke({
            "original_question": user_input,
            "chat_history": chat_history_str,
            "stage3_validation": stage3_validation
        })

        if verbose:
            parsed = self.parser.parse(output)
            print(f"æœ€ç»ˆç­”æ¡ˆ: {parsed.get('answer', output)[:500]}...")

        return output

    def _format_chat_history(self, messages) -> str:
        """
        æ ¼å¼åŒ–èŠå¤©å†å²ä¸ºå­—ç¬¦ä¸²

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–çš„å†å²å­—ç¬¦ä¸²
        """
        if not messages:
            return "æ— å†å²è®°å½•"

        formatted = []
        for i, msg in enumerate(messages):
            if hasattr(msg, 'content'):
                content = msg.content
            elif isinstance(msg, dict):
                content = msg.get('content', msg.get('output', str(msg)))
            else:
                content = str(msg)

            formatted.append(f"[{i+1}] {content[:200]}...")

        return "\n".join(formatted)


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

def quick_run(question: str, model: str = "deepseek-r1:32b", verbose: bool = True) -> str:
    """
    å¿«é€Ÿè¿è¡Œæ¥å£

    Args:
        question: é—®é¢˜
        model: æ¨¡å‹åç§°
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

    Returns:
        ç­”æ¡ˆ
    """
    agent = DeepSeekR1AgentV2(
        model=model,
        enable_tools=True,
        enable_loop_detection=True,
        enable_hallucination_detection=False  # é»˜è®¤å…³é—­ä»¥æé«˜é€Ÿåº¦
    )
    return agent.run(question, verbose=verbose)


# ============================================================================
# ä¸»å…¥å£
# ============================================================================

if __name__ == "__main__":
    print("\n" + "="*60)
    print("DeepSeek-R1 Agent V2 - æµ‹è¯•è¿è¡Œ")
    print("="*60)

    # åˆ›å»º Agent
    agent = DeepSeekR1AgentV2(
        model=os.getenv("OLLAMA_MODEL", "deepseek-r1:32b"),
        enable_tools=True,
        enable_loop_detection=True,
        enable_hallucination_detection=False  # å¯ä»¥è®¾ç½®ä¸º True ä»¥å¯ç”¨å¹»è§‰æ£€æµ‹
    )

    # æµ‹è¯•æ¡ˆä¾‹ 1: ç®€å•æ•°å­¦é¢˜
    print("\næµ‹è¯•æ¡ˆä¾‹ 1: ç®€å•æ•°å­¦")
    question1 = "Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?"

    answer1 = agent.run(question1)
    print(f"\næœ€ç»ˆç­”æ¡ˆ: {answer1}")

    # æµ‹è¯•æ¡ˆä¾‹ 2: é—®å€™è¯­ï¼ˆåº”è¯¥ä½¿ç”¨ direct æ¨¡å¼ï¼‰
    print("\n\næµ‹è¯•æ¡ˆä¾‹ 2: é—®å€™")
    answer2 = agent.run("ä½ å¥½", mode="direct")
    print(f"\næœ€ç»ˆç­”æ¡ˆ: {answer2}")

    print("\n" + "="*60)
    print("æµ‹è¯•å®Œæˆï¼")
    print("="*60)
