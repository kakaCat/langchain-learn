#!/usr/bin/env python3
"""
å›¾åƒç†è§£ä¸å¤„ç† Demo
å®ç°å›¾åƒç‰¹å¾æå–ã€ç‰©ä½“è¯†åˆ«ã€åœºæ™¯ç†è§£ã€OCR æ–‡å­—è¯†åˆ«ç­‰åŠŸèƒ½
"""

import os
import json
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from pathlib import Path
import base64
from PIL import Image
import io


@dataclass
class ImageAnalysisResult:
    """å›¾åƒåˆ†æç»“æœæ•°æ®ç±»"""
    objects: List[Dict[str, Any]]  # æ£€æµ‹åˆ°çš„ç‰©ä½“
    scenes: List[str]  # åœºæ™¯æ ‡ç­¾
    text_content: Optional[str]  # OCR è¯†åˆ«çš„æ–‡å­—
    features: Dict[str, Any]  # å›¾åƒç‰¹å¾
    metadata: Dict[str, Any]  # å…ƒæ•°æ®


@dataclass
class ObjectDetection:
    """ç‰©ä½“æ£€æµ‹ç»“æœ"""
    label: str
    confidence: float
    bbox: List[float]  # [x, y, width, height]


class ImageUnderstandingProcessor:
    """å›¾åƒç†è§£å¤„ç†å™¨"""
    
    def __init__(self):
        self.supported_formats = ['.jpg', '.jpeg', '.png', '.webp']
        
    def load_image(self, image_path: str) -> Optional[Image.Image]:
        """åŠ è½½å›¾åƒæ–‡ä»¶"""
        try:
            if not os.path.exists(image_path):
                print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                return None
                
            file_ext = Path(image_path).suffix.lower()
            if file_ext not in self.supported_formats:
                print(f"âŒ ä¸æ”¯æŒçš„å›¾åƒæ ¼å¼: {file_ext}")
                return None
                
            image = Image.open(image_path)
            print(f"âœ… æˆåŠŸåŠ è½½å›¾åƒ: {image_path} ({image.size})")
            return image
            
        except Exception as e:
            print(f"âŒ åŠ è½½å›¾åƒå¤±è´¥: {e}")
            return None
    
    def extract_features(self, image: Image.Image) -> Dict[str, Any]:
        """æå–å›¾åƒåŸºç¡€ç‰¹å¾"""
        features = {
            "dimensions": image.size,
            "mode": image.mode,
            "format": image.format,
            "aspect_ratio": image.width / image.height if image.height > 0 else 0
        }
        return features
    
    def detect_objects(self, image: Image.Image) -> List[ObjectDetection]:
        """ç‰©ä½“æ£€æµ‹ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šé›†æˆ YOLOã€Detectron2 ç­‰ç›®æ ‡æ£€æµ‹æ¨¡å‹
        objects = [
            ObjectDetection(label="person", confidence=0.95, bbox=[100, 150, 200, 300]),
            ObjectDetection(label="car", confidence=0.87, bbox=[300, 200, 150, 100]),
            ObjectDetection(label="tree", confidence=0.78, bbox=[50, 50, 100, 150])
        ]
        return objects
    
    def recognize_scenes(self, image: Image.Image) -> List[str]:
        """åœºæ™¯è¯†åˆ«ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šé›†æˆåœºæ™¯åˆ†ç±»æ¨¡å‹
        scenes = ["outdoor", "urban", "daytime", "street"]
        return scenes
    
    def extract_text(self, image: Image.Image) -> Optional[str]:
        """OCR æ–‡å­—è¯†åˆ«ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šé›†æˆ Tesseractã€EasyOCR ç­‰ OCR å¼•æ“
        text_content = "ç¤ºä¾‹æ–‡å­—ï¼šæ¬¢è¿ä½¿ç”¨å¤šæ¨¡æ€å›¾åƒå¤„ç†ç³»ç»Ÿ"
        return text_content
    
    def analyze_image(self, image_path: str) -> Optional[ImageAnalysisResult]:
        """ç»¼åˆåˆ†æå›¾åƒ"""
        print(f"ğŸ” å¼€å§‹åˆ†æå›¾åƒ: {image_path}")
        
        image = self.load_image(image_path)
        if not image:
            return None
        
        # æå–ç‰¹å¾
        features = self.extract_features(image)
        print(f"ğŸ“Š å›¾åƒç‰¹å¾: {features}")
        
        # ç‰©ä½“æ£€æµ‹
        objects = self.detect_objects(image)
        print(f"ğŸ¯ æ£€æµ‹åˆ° {len(objects)} ä¸ªç‰©ä½“")
        
        # åœºæ™¯è¯†åˆ«
        scenes = self.recognize_scenes(image)
        print(f"ğŸï¸ åœºæ™¯æ ‡ç­¾: {scenes}")
        
        # æ–‡å­—è¯†åˆ«
        text_content = self.extract_text(image)
        if text_content:
            print(f"ğŸ“ è¯†åˆ«æ–‡å­—: {text_content}")
        
        # æ„å»ºç»“æœ
        result = ImageAnalysisResult(
            objects=[{"label": obj.label, "confidence": obj.confidence, "bbox": obj.bbox} 
                    for obj in objects],
            scenes=scenes,
            text_content=text_content,
            features=features,
            metadata={
                "processing_time": "0.5s",
                "model_version": "v1.0",
                "image_size": f"{image.width}x{image.height}"
            }
        )
        
        print("âœ… å›¾åƒåˆ†æå®Œæˆ")
        return result
    
    def save_analysis_result(self, result: ImageAnalysisResult, output_path: str):
        """ä¿å­˜åˆ†æç»“æœåˆ° JSON æ–‡ä»¶"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump({
                    "objects": result.objects,
                    "scenes": result.scenes,
                    "text_content": result.text_content,
                    "features": result.features,
                    "metadata": result.metadata
                }, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")


def demo_image_understanding():
    """æ¼”ç¤ºå›¾åƒç†è§£åŠŸèƒ½"""
    print("ğŸš€ å¼€å§‹å›¾åƒç†è§£æ¼”ç¤º")
    print("=" * 50)
    
    processor = ImageUnderstandingProcessor()
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒï¼ˆåœ¨å®é™…åº”ç”¨ä¸­è¿™é‡Œä¼šä½¿ç”¨çœŸå®å›¾åƒæ–‡ä»¶ï¼‰
    test_image_path = "test_image.jpg"
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾åƒ
    try:
        # åˆ›å»ºä¸€ä¸ªçº¢è‰²çŸ©å½¢å›¾åƒ
        test_image = Image.new('RGB', (640, 480), color='red')
        test_image.save(test_image_path)
        print(f"ğŸ“¸ åˆ›å»ºæµ‹è¯•å›¾åƒ: {test_image_path}")
    except Exception as e:
        print(f"âŒ åˆ›å»ºæµ‹è¯•å›¾åƒå¤±è´¥: {e}")
        return
    
    # åˆ†æå›¾åƒ
    result = processor.analyze_image(test_image_path)
    
    if result:
        print("\nğŸ“‹ åˆ†æç»“æœæ‘˜è¦:")
        print(f"   ç‰©ä½“æ•°é‡: {len(result.objects)}")
        print(f"   åœºæ™¯æ ‡ç­¾: {', '.join(result.scenes)}")
        print(f"   å›¾åƒå°ºå¯¸: {result.features['dimensions']}")
        print(f"   æ–‡å­—å†…å®¹: {result.text_content}")
        
        # ä¿å­˜ç»“æœ
        output_path = "image_analysis_result.json"
        processor.save_analysis_result(result, output_path)
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(test_image_path):
            os.remove(test_image_path)
            print(f"ğŸ—‘ï¸ æ¸…ç†æµ‹è¯•æ–‡ä»¶: {test_image_path}")
    
    print("\nâœ… å›¾åƒç†è§£æ¼”ç¤ºå®Œæˆ")


if __name__ == "__main__":
    demo_image_understanding()