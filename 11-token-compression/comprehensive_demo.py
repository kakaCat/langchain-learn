#!/usr/bin/env python3
"""
Token å‹ç¼©ç»¼åˆæ¼”ç¤º
å±•ç¤ºæ‰€æœ‰å‹ç¼©ç­–ç•¥ã€è¯„ä¼°å’Œç›‘æ§åŠŸèƒ½
"""

import time
import json
from typing import List, Dict, Any
from token_compression_demo import (
    TokenCompressor, SummaryCompressor, 
    DeduplicationCompressor, ContextMinimizer,
    CompressionResult
)
from compression_evaluator import CompressionEvaluator
from performance_monitor import PerformanceMonitor, PerformanceMetrics
from datetime import datetime


class ComprehensiveDemo:
    """ç»¼åˆæ¼”ç¤ºç±»"""
    
    def __init__(self):
        self.compressors = [
            SummaryCompressor(max_summary_length=100),
            DeduplicationCompressor(),
            ContextMinimizer(max_context_length=50)
        ]
        self.evaluator = CompressionEvaluator()
        self.monitor = PerformanceMonitor()
    
    def demo_basic_compression(self) -> None:
        """æ¼”ç¤ºåŸºç¡€å‹ç¼©åŠŸèƒ½"""
        print("\n" + "=" * 60)
        print("ğŸ”§ åŸºç¡€å‹ç¼©ç­–ç•¥æ¼”ç¤º")
        print("=" * 60)
        
        test_text = """
        Natural language processing (NLP) is a subfield of linguistics, computer science, 
        and artificial intelligence concerned with the interactions between computers and human language.
        It focuses on how to program computers to process and analyze large amounts of natural language data.
        The goal is a computer capable of understanding the contents of documents, including the contextual nuances.
        """
        
        print(f"åŸå§‹æ–‡æœ¬ (çº¦ {len(test_text)} å­—ç¬¦):")
        print(test_text[:200] + "..." if len(test_text) > 200 else test_text)
        print()
        
        for compressor in self.compressors:
            print(f"\nğŸ“‹ ä½¿ç”¨ {compressor.name}:")
            
            start_time = time.time()
            result = compressor.compress(test_text)
            end_time = time.time()
            
            print(f"   å‹ç¼©ç»“æœ: {result.compressed_text}")
            print(f"   å‹ç¼©ç‡: {result.compression_ratio:.2%}")
            print(f"   Token èŠ‚çœ: {result.original_tokens} â†’ {result.compressed_tokens} (èŠ‚çœ {result.original_tokens - result.compressed_tokens})")
            print(f"   æ‰§è¡Œæ—¶é—´: {end_time - start_time:.4f}s")
            print(f"   æˆæœ¬èŠ‚çœ: ${result.cost_savings:.6f}")
    
    def demo_evaluation(self) -> None:
        """æ¼”ç¤ºè¯„ä¼°åŠŸèƒ½"""
        print("\n" + "=" * 60)
        print("ğŸ“Š å‹ç¼©ç­–ç•¥è¯„ä¼°æ¼”ç¤º")
        print("=" * 60)
        
        print("æ­£åœ¨è¯„ä¼°ä¸åŒå‹ç¼©ç­–ç•¥...")
        comparison_results = self.evaluator.compare_strategies(self.compressors)
        
        report = self.evaluator.generate_report(comparison_results)
        report_data = json.loads(report)
        
        # æ˜¾ç¤ºè¯„ä¼°æ‘˜è¦
        print("\nğŸ“ˆ è¯„ä¼°æ‘˜è¦:")
        for strategy_name, stats in report_data["summary"].items():
            print(f"\n  {strategy_name}:")
            print(f"    å¹³å‡å‹ç¼©ç‡: {stats['average_compression_ratio']:.2%}")
            print(f"    å¹³å‡è´¨é‡åˆ†æ•°: {stats['average_quality_score']:.2f}")
            print(f"    å¹³å‡æ‰§è¡Œæ—¶é—´: {stats['average_execution_time']:.4f}s")
        
        # æ˜¾ç¤ºæ¨è
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        for recommendation in report_data["recommendations"]:
            print(f"  - {recommendation}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        with open("compression_evaluation_demo.json", "w", encoding="utf-8") as f:
            f.write(report)
        print("\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: compression_evaluation_demo.json")
    
    def demo_performance_monitoring(self) -> None:
        """æ¼”ç¤ºæ€§èƒ½ç›‘æ§åŠŸèƒ½"""
        print("\n" + "=" * 60)
        print("ğŸ“ˆ æ€§èƒ½ç›‘æ§æ¼”ç¤º")
        print("=" * 60)
        
        # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®è®°å½•
        test_texts = [
            "Hello world! This is a short test message.",
            "Natural language processing is important for AI applications.",
            "Token compression helps reduce API costs and improve efficiency."
        ]
        
        print("è®°å½•æ€§èƒ½æ•°æ®...")
        for i, text in enumerate(test_texts):
            for compressor in self.compressors:
                start_time = time.time()
                result = compressor.compress(text)
                end_time = time.time()
                
                # è®°å½•æ€§èƒ½æŒ‡æ ‡
                metrics = PerformanceMetrics(
                    timestamp=datetime.now(),
                    strategy_name=compressor.name,
                    compression_ratio=result.compression_ratio,
                    execution_time=end_time - start_time,
                    tokens_saved=result.original_tokens - result.compressed_tokens,
                    quality_score=0.8 - (i * 0.05)  # æ¨¡æ‹Ÿè´¨é‡å˜åŒ–
                )
                
                self.monitor.record_metrics(compressor.name, metrics)
            
            print(f"  å·²å®Œæˆ {i + 1}/{len(test_texts)} è½®æ•°æ®è®°å½•")
            time.sleep(0.5)
        
        # ç”Ÿæˆç›‘æ§æŠ¥å‘Š
        print("\nç”Ÿæˆæ€§èƒ½ç›‘æ§æŠ¥å‘Š...")
        report = self.monitor.get_comparison_report()
        
        print("\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        for strategy_name, stats in report["strategies"].items():
            print(f"\n  {strategy_name}:")
            print(f"    è¿è¡Œæ¬¡æ•°: {stats['total_runs']}")
            print(f"    å¹³å‡å‹ç¼©ç‡: {stats['avg_compression_ratio']:.2%}")
            print(f"    å¹³å‡æ‰§è¡Œæ—¶é—´: {stats['avg_execution_time']:.4f}s")
            print(f"    ç´¯è®¡èŠ‚çœ Token: {stats['total_tokens_saved']}")
        
        # å¯¼å‡ºå†å²æ•°æ®
        self.monitor.export_history("performance_monitoring_demo.json")
        print("\nç›‘æ§æ•°æ®å·²å¯¼å‡ºåˆ°: performance_monitoring_demo.json")
    
    def demo_advanced_features(self) -> None:
        """æ¼”ç¤ºé«˜çº§åŠŸèƒ½"""
        print("\n" + "=" * 60)
        print("ğŸš€ é«˜çº§åŠŸèƒ½æ¼”ç¤º")
        print("=" * 60)
        
        # æ¼”ç¤ºæ‰¹é‡å¤„ç†
        print("\nğŸ“¦ æ‰¹é‡å‹ç¼©æ¼”ç¤º:")
        texts = [
            "First document with important information.",
            "Second document containing similar content to first.",
            "Third document with unique data points."
        ]
        
        for compressor in self.compressors:
            print(f"\n  ä½¿ç”¨ {compressor.name} æ‰¹é‡å¤„ç†:")
            total_saved = 0
            
            for i, text in enumerate(texts):
                result = compressor.compress(text)
                saved = result.original_tokens - result.compressed_tokens
                total_saved += saved
                print(f"    æ–‡æ¡£ {i + 1}: èŠ‚çœ {saved} tokens")
            
            print(f"    æ€»è®¡èŠ‚çœ: {total_saved} tokens")
        
        # æ¼”ç¤ºè´¨é‡ä¸æˆæœ¬çš„æƒè¡¡
        print("\nâš–ï¸ è´¨é‡ä¸æˆæœ¬æƒè¡¡:")
        long_text = "This is a very long text that needs compression. " * 10
        
        # ä¸åŒå‹ç¼©å¼ºåº¦çš„æ¯”è¾ƒ
        compressors_with_settings = [
            SummaryCompressor(max_summary_length=50),
            SummaryCompressor(max_summary_length=100),
            SummaryCompressor(max_summary_length=200)
        ]
        
        for compressor in compressors_with_settings:
            result = compressor.compress(long_text)
            print(f"\n  {compressor.name} (max_length={compressor.max_summary_length}):")
            print(f"    å‹ç¼©ç‡: {result.compression_ratio:.2%}")
            print(f"    è´¨é‡ä¼°è®¡: {result.quality_score:.2f}")
            print(f"    æˆæœ¬èŠ‚çœ: ${result.cost_savings:.6f}")
    
    def run_complete_demo(self) -> None:
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        print("ğŸš€ Token å‹ç¼©ç»¼åˆæ¼”ç¤ºå¼€å§‹")
        print("=" * 60)
        
        # æ‰§è¡Œå„ä¸ªæ¼”ç¤ºç¯èŠ‚
        self.demo_basic_compression()
        self.demo_evaluation()
        self.demo_performance_monitoring()
        self.demo_advanced_features()
        
        print("\n" + "=" * 60)
        print("âœ… ç»¼åˆæ¼”ç¤ºå®Œæˆ")
        print("=" * 60)
        print("\nç”Ÿæˆçš„æ–‡ä»¶:")
        print("  - compression_evaluation_demo.json (è¯„ä¼°æŠ¥å‘Š)")
        print("  - performance_monitoring_demo.json (ç›‘æ§æ•°æ®)")
        print("\nä¸‹ä¸€æ­¥å»ºè®®:")
        print("  1. æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶äº†è§£è¯¦ç»†æ•°æ®")
        print("  2. æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´å‹ç¼©ç­–ç•¥å‚æ•°")
        print("  3. åœ¨ç”Ÿäº§ç¯å¢ƒä¸­é›†æˆæ€§èƒ½ç›‘æ§")


def main():
    """ä¸»å‡½æ•°"""
    demo = ComprehensiveDemo()
    demo.run_complete_demo()


if __name__ == "__main__":
    main()