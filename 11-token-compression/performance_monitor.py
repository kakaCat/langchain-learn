#!/usr/bin/env python3
"""
Token å‹ç¼©æ€§èƒ½ç›‘æ§å™¨
å®æ—¶ç›‘æ§å‹ç¼©ç­–ç•¥çš„æ€§èƒ½æŒ‡æ ‡
"""

import time
import threading
import json
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime
from collections import deque


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""
    timestamp: datetime
    strategy_name: str
    compression_ratio: float
    execution_time: float
    tokens_saved: int
    quality_score: float


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, max_history: int = 1000):
        self.metrics_history: Dict[str, deque] = {}
        self.max_history = max_history
        self.lock = threading.Lock()
        self.alerts: List[str] = []
    
    def record_metrics(self, strategy_name: str, metrics: PerformanceMetrics) -> None:
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        with self.lock:
            if strategy_name not in self.metrics_history:
                self.metrics_history[strategy_name] = deque(maxlen=self.max_history)
            
            self.metrics_history[strategy_name].append(metrics)
            
            # æ£€æŸ¥æ€§èƒ½å¼‚å¸¸
            self._check_performance_anomalies(strategy_name, metrics)
    
    def _check_performance_anomalies(self, strategy_name: str, metrics: PerformanceMetrics) -> None:
        """æ£€æŸ¥æ€§èƒ½å¼‚å¸¸"""
        history = self.metrics_history[strategy_name]
        
        if len(history) < 5:  # éœ€è¦æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®
            return
        
        # è®¡ç®—æœ€è¿‘5æ¬¡çš„å¹³å‡å€¼
        recent_metrics = list(history)[-5:]
        avg_time = sum(m.execution_time for m in recent_metrics) / 5
        avg_ratio = sum(m.compression_ratio for m in recent_metrics) / 5
        
        # æ£€æµ‹æ‰§è¡Œæ—¶é—´å¼‚å¸¸
        if metrics.execution_time > avg_time * 2:
            alert = f"è­¦å‘Š: {strategy_name} æ‰§è¡Œæ—¶é—´å¼‚å¸¸å¢åŠ  ({metrics.execution_time:.4f}s > å¹³å‡ {avg_time:.4f}s)"
            self.alerts.append(alert)
        
        # æ£€æµ‹å‹ç¼©ç‡å¼‚å¸¸ä¸‹é™
        if metrics.compression_ratio < avg_ratio * 0.7:
            alert = f"è­¦å‘Š: {strategy_name} å‹ç¼©ç‡å¼‚å¸¸ä¸‹é™ ({metrics.compression_ratio:.2%} < å¹³å‡ {avg_ratio:.2%})"
            self.alerts.append(alert)
    
    def get_strategy_stats(self, strategy_name: str) -> Optional[Dict[str, Any]]:
        """è·å–ç­–ç•¥ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            if strategy_name not in self.metrics_history:
                return None
            
            metrics_list = list(self.metrics_history[strategy_name])
            
            if not metrics_list:
                return None
            
            return {
                "total_runs": len(metrics_list),
                "avg_compression_ratio": sum(m.compression_ratio for m in metrics_list) / len(metrics_list),
                "avg_execution_time": sum(m.execution_time for m in metrics_list) / len(metrics_list),
                "total_tokens_saved": sum(m.tokens_saved for m in metrics_list),
                "avg_quality_score": sum(m.quality_score for m in metrics_list) / len(metrics_list),
                "last_updated": metrics_list[-1].timestamp.isoformat()
            }
    
    def get_comparison_report(self) -> Dict[str, Any]:
        """è·å–ç­–ç•¥æ¯”è¾ƒæŠ¥å‘Š"""
        with self.lock:
            report = {
                "timestamp": datetime.now().isoformat(),
                "strategies": {},
                "alerts": self.alerts.copy(),
                "recommendations": []
            }
            
            for strategy_name in self.metrics_history:
                stats = self.get_strategy_stats(strategy_name)
                if stats:
                    report["strategies"][strategy_name] = stats
            
            # ç”Ÿæˆæ¨è
            self._generate_recommendations(report)
            
            return report
    
    def _generate_recommendations(self, report: Dict[str, Any]) -> None:
        """ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        strategies = list(report["strategies"].keys())
        
        if len(strategies) < 2:
            return
        
        # æ‰¾å‡ºæœ€ä½³ç­–ç•¥
        best_compression = max(
            strategies,
            key=lambda s: report["strategies"][s]["avg_compression_ratio"]
        )
        
        best_quality = max(
            strategies,
            key=lambda s: report["strategies"][s]["avg_quality_score"]
        )
        
        fastest = min(
            strategies,
            key=lambda s: report["strategies"][s]["avg_execution_time"]
        )
        
        report["recommendations"] = [
            f"æ¨èä½¿ç”¨ {best_compression} ä»¥è·å¾—æœ€ä½³å‹ç¼©ç‡",
            f"æ¨èä½¿ç”¨ {best_quality} ä»¥è·å¾—æœ€ä½³è´¨é‡",
            f"æ¨èä½¿ç”¨ {fastest} ä»¥è·å¾—æœ€å¿«æ‰§è¡Œé€Ÿåº¦",
            f"ç´¯è®¡èŠ‚çœ Token æ•°é‡: {sum(report['strategies'][s]['total_tokens_saved'] for s in strategies)}"
        ]
    
    def clear_alerts(self) -> None:
        """æ¸…é™¤è­¦æŠ¥"""
        with self.lock:
            self.alerts.clear()
    
    def export_history(self, filepath: str) -> None:
        """å¯¼å‡ºå†å²æ•°æ®"""
        with self.lock:
            export_data = {
                "export_timestamp": datetime.now().isoformat(),
                "metrics_history": {}
            }
            
            for strategy_name, metrics_deque in self.metrics_history.items():
                export_data["metrics_history"][strategy_name] = [
                    {
                        "timestamp": m.timestamp.isoformat(),
                        "compression_ratio": m.compression_ratio,
                        "execution_time": m.execution_time,
                        "tokens_saved": m.tokens_saved,
                        "quality_score": m.quality_score
                    }
                    for m in metrics_deque
                ]
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)


class RealTimeMonitor:
    """å®æ—¶ç›‘æ§å™¨"""
    
    def __init__(self, monitor: PerformanceMonitor):
        self.monitor = monitor
        self.running = False
        self.thread: Optional[threading.Thread] = None
    
    def start_monitoring(self, interval: int = 60) -> None:
        """å¼€å§‹å®æ—¶ç›‘æ§"""
        if self.running:
            print("ç›‘æ§å™¨å·²åœ¨è¿è¡Œä¸­")
            return
        
        self.running = True
        self.thread = threading.Thread(target=self._monitoring_loop, args=(interval,))
        self.thread.daemon = True
        self.thread.start()
        
        print(f"å®æ—¶ç›‘æ§å·²å¯åŠ¨ï¼Œæ¯ {interval} ç§’ç”Ÿæˆä¸€æ¬¡æŠ¥å‘Š")
    
    def stop_monitoring(self) -> None:
        """åœæ­¢å®æ—¶ç›‘æ§"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=5)
        print("å®æ—¶ç›‘æ§å·²åœæ­¢")
    
    def _monitoring_loop(self, interval: int) -> None:
        """ç›‘æ§å¾ªç¯"""
        while self.running:
            time.sleep(interval)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = self.monitor.get_comparison_report()
            
            # è¾“å‡ºæ‘˜è¦ä¿¡æ¯
            self._print_report_summary(report)
            
            # ä¿å­˜æŠ¥å‘Š
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"performance_report_{timestamp}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
    
    def _print_report_summary(self, report: Dict[str, Any]) -> None:
        """æ‰“å°æŠ¥å‘Šæ‘˜è¦"""
        print("\n" + "=" * 60)
        print(f"æ€§èƒ½ç›‘æ§æŠ¥å‘Š - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)
        
        for strategy_name, stats in report["strategies"].items():
            print(f"\nç­–ç•¥: {strategy_name}")
            print(f"  è¿è¡Œæ¬¡æ•°: {stats['total_runs']}")
            print(f"  å¹³å‡å‹ç¼©ç‡: {stats['avg_compression_ratio']:.2%}")
            print(f"  å¹³å‡æ‰§è¡Œæ—¶é—´: {stats['avg_execution_time']:.4f}s")
            print(f"  å¹³å‡è´¨é‡åˆ†æ•°: {stats['avg_quality_score']:.2f}")
            print(f"  ç´¯è®¡èŠ‚çœ Token: {stats['total_tokens_saved']}")
        
        if report["alerts"]:
            print(f"\nâš ï¸  è­¦æŠ¥ ({len(report['alerts'])} æ¡):")
            for alert in report["alerts"][-5:]:  # åªæ˜¾ç¤ºæœ€è¿‘5æ¡è­¦æŠ¥
                print(f"  - {alert}")
        
        if report["recommendations"]:
            print(f"\nğŸ’¡ æ¨è:")
            for rec in report["recommendations"]:
                print(f"  - {rec}")


def demo_monitoring():
    """æ¼”ç¤ºç›‘æ§åŠŸèƒ½"""
    print("=== Token å‹ç¼©æ€§èƒ½ç›‘æ§æ¼”ç¤º ===")
    
    # åˆ›å»ºç›‘æ§å™¨
    monitor = PerformanceMonitor()
    realtime_monitor = RealTimeMonitor(monitor)
    
    # æ¨¡æ‹Ÿä¸€äº›æ€§èƒ½æ•°æ®
    strategies = ["æ‘˜è¦å‹ç¼©", "å»é‡å‹ç¼©", "ä¸Šä¸‹æ–‡æœ€å°åŒ–"]
    
    print("\næ¨¡æ‹Ÿæ€§èƒ½æ•°æ®è®°å½•...")
    for i in range(10):
        for strategy in strategies:
            metrics = PerformanceMetrics(
                timestamp=datetime.now(),
                strategy_name=strategy,
                compression_ratio=0.7 + (i * 0.02),  # æ¨¡æ‹Ÿé€æ¸æ”¹å–„çš„å‹ç¼©ç‡
                execution_time=0.1 + (i * 0.01),     # æ¨¡æ‹Ÿé€æ¸å¢åŠ çš„æ‰§è¡Œæ—¶é—´
                tokens_saved=100 + (i * 20),         # æ¨¡æ‹Ÿé€æ¸å¢åŠ çš„èŠ‚çœé‡
                quality_score=0.8 - (i * 0.01)       # æ¨¡æ‹Ÿé€æ¸ä¸‹é™çš„è´¨é‡
            )
            monitor.record_metrics(strategy, metrics)
        time.sleep(0.5)
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\nç”Ÿæˆæ€§èƒ½æŠ¥å‘Š...")
    report = monitor.get_comparison_report()
    
    print(json.dumps(report, indent=2, ensure_ascii=False))
    
    # å¯¼å‡ºå†å²æ•°æ®
    monitor.export_history("performance_history.json")
    print("\nå†å²æ•°æ®å·²å¯¼å‡ºåˆ°: performance_history.json")


if __name__ == "__main__":
    demo_monitoring()