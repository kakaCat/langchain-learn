#!/usr/bin/env python3
"""
å›½é™…åŒ–æ¨¡æ¿ç¤ºä¾‹ï¼šæ ¹æ®ç›®æ ‡è¯­è¨€ç”Ÿæˆå¹¿å‘Šæ–‡æ¡ˆ

åŠŸèƒ½è¦ç‚¹ï¼š
- ä½¿ç”¨ PromptTemplate æ„å»ºå¤šè¯­è¨€æç¤ºè¯
- é€šè¿‡è¯­è¨€ä»£ç æ§åˆ¶è¾“å‡ºè¯­è¨€ï¼ˆzh-CNã€en-USã€ja-JP ç­‰ï¼‰
- ç»Ÿä¸€çš„ç¯å¢ƒåŠ è½½ä¸ LLM åˆå§‹åŒ–
- åŸºæœ¬å¼‚å¸¸å¤„ç†ï¼Œç¡®ä¿ç¤ºä¾‹ç¨³å®šè¿è¡Œ
"""

from __future__ import annotations

import os
from typing import Dict
from dotenv import load_dotenv
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# ä»å½“å‰æ¨¡å—ç›®å½•åŠ è½½ .env

def load_environment() -> None:
    load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), ".env"), override=False)


def get_llm() -> ChatOpenAI:
    """åˆ›å»ºå¹¶é…ç½®è¯­è¨€æ¨¡å‹å®ä¾‹"""
    api_key = os.getenv("OPENAI_API_KEY")
    model = os.getenv("OPENAI_MODEL", "deepseek-chat")
    base_url = os.getenv("OPENAI_BASE_URL")
    temperature = float(os.getenv("OPENAI_TEMPERATURE", "0"))
    max_tokens = int(os.getenv("OPENAI_MAX_TOKENS", "512"))
    kwargs = {
        "model": model,
        "api_key": api_key,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "timeout": 120,
        "max_retries": 3,
        "request_timeout": 120,
        "verbose": False,
        "base_url": base_url,
    }
    return ChatOpenAI(**kwargs)


LANG_MAP: Dict[str, str] = {
    "zh-CN": "è¯·ç”¨ä¸­æ–‡ä¸º{product}åˆ›ä½œ{style}é£æ ¼çš„å¹¿å‘Šæ–‡æ¡ˆï¼Œå¹¶ä¿æŒåœ°é“è¡¨è¾¾ã€‚",
    "en-US": "Please write an {style} style ad copy for {product} in natural American English.",
    "ja-JP": "{product}ã®ãŸã‚ã«{style}ã‚¹ã‚¿ã‚¤ãƒ«ã®åºƒå‘Šã‚³ãƒ”ãƒ¼ã‚’ã€æ—¥æœ¬èªã§è‡ªç„¶ã«ä½œæˆã—ã¦ãã ã•ã„ã€‚",
}


def build_prompt(language: str) -> PromptTemplate:
    template = LANG_MAP.get(
        language,
        "Please write an {style} style ad copy for {product} in the specified language.",
    )
    return PromptTemplate.from_template(template)


def main() -> None:
    print("ğŸ”„ æ­£åœ¨åŠ è½½ç¯å¢ƒé…ç½®...")
    load_environment()
    print("=== å›½é™…åŒ–æ¨¡æ¿ç¤ºä¾‹ï¼šå¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆ ===")

    # ç¤ºä¾‹è¾“å…¥
    tests = [
        {"product": "æ™ºèƒ½æ‰‹æœº", "style": "ç§‘å¹»", "language": "zh-CN"},
        {"product": "smartwatch", "style": "tech", "language": "en-US"},
        {"product": "é›»æ°—è‡ªå‹•è»Š", "style": "ã‚¨ã‚³", "language": "ja-JP"},
        {"product": "æ™ºèƒ½å®¶å±…ç³»ç»Ÿ", "style": "æ¸©é¦¨", "language": "unknown"},
    ]

    for t in tests:
        product = t["product"]
        style = t["style"]
        language = t["language"]
        prompt = build_prompt(language)
        final_prompt = prompt.format(product=product, style=style)
        print(f"\nè¯­è¨€ï¼š{language} | äº§å“ï¼š{product} | é£æ ¼ï¼š{style}")
        print("æç¤ºè¯ï¼š")
        print(final_prompt)
        print("-" * 30)
        try:
            llm = get_llm()
            response = llm.invoke(final_prompt)
            print("æ¨¡å‹å›å¤ï¼š")
            print(response.content)
        except Exception as e:
            print("âŒ è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ .env é…ç½®ï¼ˆOPENAI_API_KEY/OPENAI_BASE_URL/OPENAI_MODELï¼‰æˆ–ç½‘ç»œã€‚")
            print(f"é”™è¯¯è¯¦æƒ…ï¼š{e}")


if __name__ == "__main__":
    main()