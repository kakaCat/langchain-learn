#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ - éªŒè¯å¢å¼ºç‰ˆ Agent çš„ç¯å¢ƒé…ç½®

è¿è¡Œæ­¤è„šæœ¬ä»¥æ£€æŸ¥ï¼š
1. ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…
2. ç¯å¢ƒå˜é‡æ˜¯å¦é…ç½®
3. LLM è¿æ¥æ˜¯å¦æ­£å¸¸
4. å·¥å…·æ˜¯å¦å¯ç”¨
"""

import os
import sys
from typing import List, Tuple


def check_imports() -> List[Tuple[str, bool, str]]:
    """æ£€æŸ¥å¿…éœ€çš„åŒ…æ˜¯å¦å·²å®‰è£…"""
    results = []

    packages = [
        ("langchain", "LangChain æ ¸å¿ƒåº“"),
        ("langchain_core", "LangChain æ ¸å¿ƒç»„ä»¶"),
        ("langgraph", "LangGraph å·¥ä½œæµå¼•æ“"),
        ("pydantic", "æ•°æ®éªŒè¯åº“"),
        ("dotenv", "ç¯å¢ƒå˜é‡ç®¡ç†"),
        ("langchain_openai", "OpenAI é›†æˆï¼ˆå¦‚æœä½¿ç”¨ OpenAIï¼‰"),
        ("langchain_ollama", "Ollama é›†æˆï¼ˆå¦‚æœä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼‰"),
        ("langchain_community", "ç¤¾åŒºå·¥å…·é›†æˆ"),
        ("duckduckgo_search", "Web æœç´¢å·¥å…·"),
        ("langchain_experimental", "å®éªŒæ€§å·¥å…·ï¼ˆPython REPLï¼‰"),
    ]

    for package, description in packages:
        try:
            __import__(package)
            results.append((package, True, description))
        except ImportError:
            results.append((package, False, description))

    return results


def check_env_vars() -> List[Tuple[str, bool, str]]:
    """æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®"""
    results = []

    # æ£€æŸ¥ .env æ–‡ä»¶
    env_path = os.path.join(os.path.dirname(__file__), ".env")
    env_exists = os.path.exists(env_path)
    results.append((".env æ–‡ä»¶", env_exists, "ä½ç½®: 10-agent-examples/.env"))

    if env_exists:
        from dotenv import load_dotenv

        load_dotenv(dotenv_path=env_path, override=False)

    # æ£€æŸ¥ LLM é…ç½®
    provider = os.getenv("LLM_PROVIDER", "").lower()
    results.append(
        ("LLM_PROVIDER", bool(provider), f"å½“å‰å€¼: {provider or 'ï¼ˆæœªè®¾ç½®ï¼‰'}")
    )

    if provider in {"openai", ""}:
        openai_key = os.getenv("OPENAI_API_KEY")
        results.append(
            ("OPENAI_API_KEY", bool(openai_key), "OpenAI API å¯†é’¥" + (" âœ“" if openai_key else ""))
        )

        openai_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        results.append(("OPENAI_MODEL", True, f"æ¨¡å‹: {openai_model}"))

    if provider in {"ollama", "local"}:
        ollama_model = os.getenv("OLLAMA_MODEL", "llama3.1:8b")
        results.append(("OLLAMA_MODEL", True, f"æ¨¡å‹: {ollama_model}"))

        ollama_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        results.append(("OLLAMA_BASE_URL", True, f"åœ°å€: {ollama_url}"))

    return results


def check_llm_connection() -> Tuple[bool, str]:
    """æµ‹è¯• LLM è¿æ¥"""
    try:
        from dotenv import load_dotenv

        load_dotenv(
            dotenv_path=os.path.join(os.path.dirname(__file__), ".env"), override=False
        )

        provider = os.getenv("LLM_PROVIDER", "").lower()
        use_ollama = provider in {"ollama", "local"} or not os.getenv("OPENAI_API_KEY")

        if use_ollama:
            from langchain_ollama import ChatOllama

            model_name = os.getenv("OLLAMA_MODEL", "llama3.1:8b")
            base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")

            llm = ChatOllama(
                model=model_name, base_url=base_url, temperature=0, timeout=10
            )
        else:
            from langchain_openai import ChatOpenAI

            api_key = os.getenv("OPENAI_API_KEY")
            base_url = os.getenv("OPENAI_BASE_URL")
            model_name = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

            llm = ChatOpenAI(
                model=model_name,
                api_key=api_key,
                base_url=base_url,
                temperature=0,
                max_tokens=50,
                timeout=10,
            )

        from langchain_core.messages import HumanMessage

        response = llm.invoke([HumanMessage(content="Say 'OK' if you can hear me.")])
        return True, f"è¿æ¥æˆåŠŸï¼å“åº”: {response.content[:50]}"

    except Exception as e:
        return False, f"è¿æ¥å¤±è´¥: {str(e)}"


def check_tools() -> List[Tuple[str, bool, str]]:
    """æ£€æŸ¥å·¥å…·å¯ç”¨æ€§"""
    results = []

    # Web æœç´¢å·¥å…·
    try:
        from langchain_community.tools import DuckDuckGoSearchRun

        search = DuckDuckGoSearchRun()
        result = search.run("test")
        results.append(("Web Search (DuckDuckGo)", True, "æœç´¢åŠŸèƒ½æ­£å¸¸"))
    except Exception as e:
        results.append(("Web Search (DuckDuckGo)", False, f"å¤±è´¥: {str(e)[:50]}"))

    # Python REPL å·¥å…·
    try:
        from langchain_experimental.utilities import PythonREPL

        repl = PythonREPL()
        result = repl.run("1 + 1")
        is_ok = "2" in str(result)
        results.append(
            ("Python REPL", is_ok, "ä»£ç æ‰§è¡Œæ­£å¸¸" if is_ok else "è¾“å‡ºå¼‚å¸¸")
        )
    except Exception as e:
        results.append(("Python REPL", False, f"å¤±è´¥: {str(e)[:50]}"))

    # æ–‡ä»¶è¯»å–å·¥å…·
    try:
        test_file = __file__
        with open(test_file, "r") as f:
            content = f.read(100)
        results.append(("File Read", True, "æ–‡ä»¶è¯»å–æ­£å¸¸"))
    except Exception as e:
        results.append(("File Read", False, f"å¤±è´¥: {str(e)[:50]}"))

    return results


def print_results(title: str, results: List[Tuple[str, bool, str]]):
    """æ‰“å°æ£€æŸ¥ç»“æœ"""
    print(f"\n{'='*70}")
    print(f"{title}")
    print(f"{'='*70}")

    for item, status, description in results:
        status_icon = "âœ…" if status else "âŒ"
        print(f"{status_icon} {item:<30} {description}")


def main():
    print("\n" + "="*70)
    print("Claude Code Style Enhanced - ç¯å¢ƒé…ç½®æ£€æŸ¥")
    print("="*70)

    # 1. æ£€æŸ¥ä¾èµ–åŒ…
    import_results = check_imports()
    print_results("1. ä¾èµ–åŒ…æ£€æŸ¥", import_results)

    # ç»Ÿè®¡å¤±è´¥çš„åŒ…
    failed_imports = [item for item, status, _ in import_results if not status]
    if failed_imports:
        print(f"\nâš ï¸  ç¼ºå°‘ {len(failed_imports)} ä¸ªä¾èµ–åŒ…ï¼Œè¯·è¿è¡Œ:")
        print(f"   pip install {' '.join(failed_imports)}")

    # 2. æ£€æŸ¥ç¯å¢ƒå˜é‡
    env_results = check_env_vars()
    print_results("2. ç¯å¢ƒå˜é‡æ£€æŸ¥", env_results)

    # 3. æ£€æŸ¥ LLM è¿æ¥
    print(f"\n{'='*70}")
    print("3. LLM è¿æ¥æµ‹è¯•")
    print(f"{'='*70}")

    if all(status for _, status, _ in import_results[:5]):  # æ ¸å¿ƒåŒ…éƒ½å®‰è£…äº†
        llm_ok, llm_msg = check_llm_connection()
        status_icon = "âœ…" if llm_ok else "âŒ"
        print(f"{status_icon} LLM è¿æ¥: {llm_msg}")
    else:
        print("â­ï¸  è·³è¿‡ï¼ˆç¼ºå°‘æ ¸å¿ƒä¾èµ–ï¼‰")

    # 4. æ£€æŸ¥å·¥å…·
    tool_results = check_tools()
    print_results("4. å·¥å…·å¯ç”¨æ€§æ£€æŸ¥", tool_results)

    # æ€»ç»“
    print(f"\n{'='*70}")
    print("æ€»ç»“")
    print(f"{'='*70}")

    all_checks = import_results + env_results + tool_results
    passed = sum(1 for _, status, _ in all_checks if status)
    total = len(all_checks)

    if llm_ok:
        passed += 1
        total += 1

    print(f"é€šè¿‡: {passed}/{total} é¡¹æ£€æŸ¥")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼ä½ å¯ä»¥è¿è¡Œå¢å¼ºç‰ˆ Agent äº†ï¼š")
        print("   python 11_claude_code_style_enhanced.py")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·æŸ¥çœ‹ä¸Šè¿°è¯¦æƒ…å¹¶ä¿®å¤é—®é¢˜ã€‚")
        print("\nå¸¸è§é—®é¢˜è§£å†³ï¼š")
        print("1. ç¼ºå°‘ä¾èµ–åŒ… â†’ pip install -r requirements.txt")
        print("2. ç¼ºå°‘ .env æ–‡ä»¶ â†’ å‚è€ƒ README_enhanced.md åˆ›å»ºé…ç½®")
        print("3. LLM è¿æ¥å¤±è´¥ â†’ æ£€æŸ¥ API Key æˆ– Ollama æœåŠ¡æ˜¯å¦è¿è¡Œ")
        print("4. Web æœç´¢å¤±è´¥ â†’ æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å®‰è£… duckduckgo-search")


if __name__ == "__main__":
    main()
