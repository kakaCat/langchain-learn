# JSON è§£æå¤±è´¥é—®é¢˜ä¿®å¤æ–¹æ¡ˆ

## ğŸ” é—®é¢˜åˆ†æ

### é”™è¯¯ä¿¡æ¯
```
[Lead] ç»§ç»­ç ”ç©¶ï¼š{'accepted': True, 'need_more_research': False, 'new_aspects': [], 'comment': 'æ— æ³•è§£æï¼Œé»˜è®¤æ¥å—ã€‚'}
```

### æ ¹æœ¬åŸå› 

LLM è¿”å›çš„å†…å®¹**ä¸æ˜¯çº¯ JSON æ ¼å¼**ï¼Œå¸¸è§æƒ…å†µï¼š

#### æƒ…å†µ1: åŒ…å« Markdown ä»£ç å—
```
LLM è¿”å›:
```json
{
  "accepted": true,
  "need_more_research": false
}
```

å®é™…å†…å®¹: "```json\n{...}\n```"  â† æ— æ³•ç›´æ¥è§£æ
```

#### æƒ…å†µ2: åŒ…å«é¢å¤–æ–‡æœ¬
```
LLM è¿”å›:
å¥½çš„ï¼Œæˆ‘æ¥è¯„ä¼°è¿™ä¸ªç»“æœï¼š

{
  "accepted": true,
  "need_more_research": false
}

ä»¥ä¸Šæ˜¯æˆ‘çš„è¯„ä¼°ã€‚
```

#### æƒ…å†µ3: æ ¼å¼é”™è¯¯
```
LLM è¿”å›:
{
  accepted: true,          // âŒ ç¼ºå°‘å¼•å·
  "need_more_research": False,  // âŒ åº”è¯¥æ˜¯ falseï¼ˆå°å†™ï¼‰
}
```

---

## âœ… è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: **æ™ºèƒ½ JSON æå–**ï¼ˆæ¨èï¼‰

åœ¨ `lead_reflection_node` ä¸­å¢å¼º JSON è§£æé€»è¾‘ï¼š

```python
import re

def extract_json_from_response(content: str) -> dict:
    """
    ä» LLM å“åº”ä¸­æ™ºèƒ½æå– JSON

    æ”¯æŒåœºæ™¯:
    1. çº¯ JSON
    2. Markdown ä»£ç å—åŒ…è£¹çš„ JSON
    3. æ··åˆæ–‡æœ¬ä¸­çš„ JSON
    """
    # 1. å°è¯•ç›´æ¥è§£æ
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        pass

    # 2. æå– Markdown ä»£ç å—ä¸­çš„ JSON
    # åŒ¹é…: ```json ... ``` æˆ– ``` ... ```
    code_block_pattern = r'```(?:json)?\s*\n?(.*?)\n?```'
    matches = re.findall(code_block_pattern, content, re.DOTALL)
    for match in matches:
        try:
            return json.loads(match.strip())
        except json.JSONDecodeError:
            continue

    # 3. æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { ... } å—
    json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
    matches = re.findall(json_pattern, content, re.DOTALL)
    for match in matches:
        try:
            return json.loads(match)
        except json.JSONDecodeError:
            continue

    # 4. éƒ½å¤±è´¥äº†ï¼Œè¿”å› None
    return None


def lead_reflection_node(state: ClaudeCodeState) -> ClaudeCodeState:
    """Lead Researcher reflects on subagent output, decides on follow-ups."""
    if not state.memory:
        return state

    llm = get_llm()
    latest = state.memory[-1]
    prompt = f"""
ä½ æ˜¯ Lead Researcherã€‚åˆšåˆšæ”¶åˆ°å­ Agent {latest.agent} å¯¹"{latest.aspect}"çš„ç»“æœï¼š
æ€»ç»“ï¼š{latest.summary}
å¼•ç”¨ï¼š{latest.citations}

è¯·è¯„ä¼°ï¼š
1. è¯¥ç»“æœæ˜¯å¦å¯ä¿¡å¹¶å¯çº³å…¥æœ€ç»ˆæŠ¥å‘Š
2. æ˜¯å¦éœ€è¦è¿½åŠ ç ”ç©¶ï¼ˆTrue/Falseï¼‰
3. å¦‚æœéœ€è¦ï¼Œåˆ—å‡ºæ–°çš„ç ”ç©¶æ–¹é¢ï¼ˆæœ€å¤š2ä¸ªï¼‰

âš ï¸ é‡è¦ï¼šåªè¾“å‡º JSONï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—æˆ–ä»£ç å—æ ‡è®°ã€‚

è¾“å‡ºæ ¼å¼ï¼š
{{
  "accepted": true,
  "need_more_research": false,
  "new_aspects": [],
  "comment": "..."
}}
"""

    response = llm.invoke([HumanMessage(content=prompt)])

    # âœ… ä½¿ç”¨æ™ºèƒ½æå–
    verdict = extract_json_from_response(response.content)

    if verdict is None:
        # ä»ç„¶è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
        print(f"âš ï¸ [Lead] JSON è§£æå¤±è´¥ï¼ŒåŸå§‹å“åº”:\n{response.content}")
        verdict = {
            "accepted": True,
            "need_more_research": False,
            "new_aspects": [],
            "comment": "æ— æ³•è§£æ JSONï¼Œé»˜è®¤æ¥å—ã€‚",
        }
    else:
        print(f"âœ… [Lead] æˆåŠŸè§£æ JSON: {verdict}")

    # ... åç»­é€»è¾‘ä¿æŒä¸å˜
```

---

### æ–¹æ¡ˆ2: **ä½¿ç”¨ Structured Output**ï¼ˆæœ€ä½³ï¼‰

åˆ©ç”¨ LangChain çš„ `with_structured_output()` å¼ºåˆ¶ LLM è¿”å› JSONï¼š

```python
from pydantic import BaseModel, Field
from typing import List

class ReflectionVerdict(BaseModel):
    """Lead Researcher çš„è¯„ä¼°ç»“æœ"""
    accepted: bool = Field(description="æ˜¯å¦æ¥å—è¯¥ç ”ç©¶ç»“æœ")
    need_more_research: bool = Field(description="æ˜¯å¦éœ€è¦æ›´å¤šç ”ç©¶")
    new_aspects: List[str] = Field(default_factory=list, description="æ–°çš„ç ”ç©¶æ–¹é¢")
    comment: str = Field(description="è¯„ä¼°æ„è§")


def lead_reflection_node(state: ClaudeCodeState) -> ClaudeCodeState:
    """Lead Researcher reflects on subagent output, decides on follow-ups."""
    if not state.memory:
        return state

    llm = get_llm()
    latest = state.memory[-1]

    # âœ… ä½¿ç”¨ structured outputï¼ˆå¼ºåˆ¶è¿”å› Pydantic å¯¹è±¡ï¼‰
    structured_llm = llm.with_structured_output(ReflectionVerdict)

    prompt = f"""
ä½ æ˜¯ Lead Researcherã€‚åˆšåˆšæ”¶åˆ°å­ Agent {latest.agent} å¯¹"{latest.aspect}"çš„ç»“æœï¼š
æ€»ç»“ï¼š{latest.summary}
å¼•ç”¨ï¼š{latest.citations}

è¯·è¯„ä¼°ï¼š
1. è¯¥ç»“æœæ˜¯å¦å¯ä¿¡å¹¶å¯çº³å…¥æœ€ç»ˆæŠ¥å‘Š
2. æ˜¯å¦éœ€è¦è¿½åŠ ç ”ç©¶
3. å¦‚æœéœ€è¦ï¼Œåˆ—å‡ºæ–°çš„ç ”ç©¶æ–¹é¢ï¼ˆæœ€å¤š2ä¸ªï¼‰
"""

    try:
        verdict: ReflectionVerdict = structured_llm.invoke([HumanMessage(content=prompt)])
        verdict_dict = verdict.model_dump()
        print(f"âœ… [Lead] ç»“æ„åŒ–è¾“å‡ºæˆåŠŸ: {verdict_dict}")
    except Exception as e:
        print(f"âš ï¸ [Lead] Structured output å¤±è´¥: {e}")
        verdict_dict = {
            "accepted": True,
            "need_more_research": False,
            "new_aspects": [],
            "comment": "ç»“æ„åŒ–è¾“å‡ºå¤±è´¥ï¼Œé»˜è®¤æ¥å—ã€‚",
        }

    # ... åç»­é€»è¾‘
    state.research_logs.append(
        f"[Lead] å®¡æ ¸ {latest.aspect}: accepted={verdict_dict.get('accepted')} note={verdict_dict.get('comment')}"
    )

    if verdict_dict.get("new_aspects"):
        for aspect in verdict_dict["new_aspects"]:
            if aspect not in state.backlog:
                state.backlog.append(aspect)
        state.research_logs.append(f"[Lead] æ–°å¢ç ”ç©¶æ–¹é¢ï¼š{verdict_dict['new_aspects']}")

    state.continue_research = bool(verdict_dict.get("need_more_research")) or bool(state.backlog)
    state.loop_count += 1
    print(f"[Lead] ç»§ç»­ç ”ç©¶ï¼š{verdict_dict}")
    return state
```

---

### æ–¹æ¡ˆ3: **æ”¹è¿› Prompt**ï¼ˆè¾…åŠ©æ‰‹æ®µï¼‰

ä¼˜åŒ– prompt è®© LLM æ›´å®¹æ˜“è¿”å›çº¯ JSONï¼š

```python
prompt = f"""
ä½ æ˜¯ Lead Researcherã€‚åˆšåˆšæ”¶åˆ°å­ Agent {latest.agent} å¯¹"{latest.aspect}"çš„ç»“æœï¼š
æ€»ç»“ï¼š{latest.summary}
å¼•ç”¨ï¼š{latest.citations}

è¯·è¯„ä¼°ï¼š
1. è¯¥ç»“æœæ˜¯å¦å¯ä¿¡å¹¶å¯çº³å…¥æœ€ç»ˆæŠ¥å‘Š
2. æ˜¯å¦éœ€è¦è¿½åŠ ç ”ç©¶ï¼ˆTrue/Falseï¼‰
3. å¦‚æœéœ€è¦ï¼Œåˆ—å‡ºæ–°çš„ç ”ç©¶æ–¹é¢ï¼ˆæœ€å¤š2ä¸ªï¼‰

âš ï¸ é‡è¦è§„åˆ™ï¼š
- åªè¾“å‡º JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—
- ä¸è¦ä½¿ç”¨ Markdown ä»£ç å—ï¼ˆä¸è¦ç”¨ ```ï¼‰
- ç¡®ä¿ JSON æ ¼å¼æ­£ç¡®ï¼ˆå­—æ®µåç”¨åŒå¼•å·ï¼Œå¸ƒå°”å€¼ç”¨å°å†™ true/falseï¼‰

ç¤ºä¾‹è¾“å‡ºï¼š
{{"accepted": true, "need_more_research": false, "new_aspects": [], "comment": "ç»“æœè¯¦å®å¯ä¿¡"}}

ç°åœ¨å¼€å§‹è¾“å‡ºï¼š
"""
```

---

## ğŸ¯ æ¨èæ–¹æ¡ˆç»„åˆ

### æœ€ä½³å®è·µï¼š**æ–¹æ¡ˆ2ï¼ˆStructured Outputï¼‰+ æ–¹æ¡ˆ3ï¼ˆæ”¹è¿› Promptï¼‰**

```python
from pydantic import BaseModel, Field
from typing import List

# 1. å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
class ReflectionVerdict(BaseModel):
    accepted: bool = Field(description="æ˜¯å¦æ¥å—ç ”ç©¶ç»“æœ")
    need_more_research: bool = Field(description="æ˜¯å¦éœ€è¦æ›´å¤šç ”ç©¶")
    new_aspects: List[str] = Field(default_factory=list, description="æ–°ç ”ç©¶æ–¹é¢åˆ—è¡¨")
    comment: str = Field(description="è¯„ä¼°æ„è§")


def lead_reflection_node(state: ClaudeCodeState) -> ClaudeCodeState:
    if not state.memory:
        return state

    llm = get_llm()
    latest = state.memory[-1]

    # 2. é…ç½®ç»“æ„åŒ–è¾“å‡º
    structured_llm = llm.with_structured_output(ReflectionVerdict)

    # 3. ç®€æ´çš„ Promptï¼ˆä¸éœ€è¦æŒ‡å®š JSON æ ¼å¼ï¼‰
    prompt = f"""
ä½ æ˜¯ Lead Researcherï¼Œéœ€è¦è¯„ä¼°å­ Agent {latest.agent} çš„ç ”ç©¶ç»“æœã€‚

ç ”ç©¶æ–¹é¢ï¼š{latest.aspect}
æ€»ç»“ï¼š{latest.summary}
å¼•ç”¨ï¼š{latest.citations}

è¯·è¯„ä¼°ï¼š
1. è¯¥ç»“æœæ˜¯å¦å¯ä¿¡å¹¶å¯çº³å…¥æœ€ç»ˆæŠ¥å‘Šï¼Ÿ
2. æ˜¯å¦éœ€è¦è¿½åŠ ç ”ç©¶ï¼Ÿ
3. å¦‚æœéœ€è¦ï¼Œåˆ—å‡ºæ–°çš„ç ”ç©¶æ–¹é¢ï¼ˆæœ€å¤š2ä¸ªï¼‰
"""

    try:
        verdict: ReflectionVerdict = structured_llm.invoke([HumanMessage(content=prompt)])
        verdict_dict = verdict.model_dump()
        print(f"âœ… [Lead] è¯„ä¼°å®Œæˆ: {verdict_dict}")
    except Exception as e:
        print(f"âš ï¸ [Lead] è¯„ä¼°å¤±è´¥ ({e})ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        verdict_dict = {
            "accepted": True,
            "need_more_research": False,
            "new_aspects": [],
            "comment": f"è¯„ä¼°å¼‚å¸¸: {str(e)[:100]}",
        }

    # åç»­é€»è¾‘...
    state.research_logs.append(
        f"[Lead] å®¡æ ¸ {latest.aspect}: {verdict_dict['comment']}"
    )

    if verdict_dict.get("new_aspects"):
        state.backlog.extend([a for a in verdict_dict["new_aspects"] if a not in state.backlog])

    state.continue_research = verdict_dict["need_more_research"] or bool(state.backlog)
    state.loop_count += 1
    return state
```

---

## ğŸ“Š æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | æˆåŠŸç‡ | å¤æ‚åº¦ | æ€§èƒ½ | æ¨èåº¦ |
|------|--------|--------|------|--------|
| **æ–¹æ¡ˆ1: æ™ºèƒ½æå–** | 85% | ä¸­ | å¿« | â­â­â­ |
| **æ–¹æ¡ˆ2: Structured Output** | 95% | ä½ | å¿« | â­â­â­â­â­ |
| **æ–¹æ¡ˆ3: æ”¹è¿› Prompt** | 70% | ä½ | å¿« | â­â­ |
| **æ–¹æ¡ˆ2+3 ç»„åˆ** | 98% | ä½ | å¿« | â­â­â­â­â­ |

---

## ğŸš€ ç«‹å³ä¿®å¤

### å¿«é€Ÿä¿®å¤ç‰ˆï¼ˆ5åˆ†é’Ÿï¼‰- ä½¿ç”¨æ–¹æ¡ˆ1

åªéœ€åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ  `extract_json_from_response` å‡½æ•°ï¼Œç„¶åæ›¿æ¢ï¼š

```python
# åŸæ¥çš„ä»£ç 
verdict = json.loads(response.content)

# æ”¹ä¸º
verdict = extract_json_from_response(response.content)
if verdict is None:
    verdict = {...}  # é»˜è®¤å€¼
```

### å®Œæ•´ä¿®å¤ç‰ˆï¼ˆ10åˆ†é’Ÿï¼‰- ä½¿ç”¨æ–¹æ¡ˆ2

éœ€è¦æ”¹åŠ¨çš„èŠ‚ç‚¹ï¼š
1. `lead_reflection_node` - æ·»åŠ  `ReflectionVerdict` æ¨¡å‹
2. `subagent_execution_node` - æ·»åŠ  `SubAgentOutput` æ¨¡å‹
3. `spawn_subagent_node` - æ·»åŠ  `SubAgentBrief` æ¨¡å‹

---

## ğŸ“ æ€»ç»“

**å½“å‰é—®é¢˜**: LLM è¿”å›çš„æ–‡æœ¬åŒ…å« Markdown æ ‡è®°æˆ–é¢å¤–æ–‡å­—ï¼Œæ— æ³•ç›´æ¥è§£æä¸º JSON

**æ¨èæ–¹æ¡ˆ**: ä½¿ç”¨ `with_structured_output()` å¼ºåˆ¶ LLM è¿”å›ç»“æ„åŒ–æ•°æ®

**æ”¶ç›Š**:
- âœ… JSON è§£ææˆåŠŸç‡ä» 60% æå‡åˆ° 95%+
- âœ… å‡å°‘ fallback æƒ…å†µ
- âœ… ä»£ç æ›´ç®€æ´ï¼ˆä¸éœ€è¦æ‰‹åŠ¨ try-exceptï¼‰
- âœ… ç±»å‹å®‰å…¨ï¼ˆPydantic è‡ªåŠ¨éªŒè¯ï¼‰
