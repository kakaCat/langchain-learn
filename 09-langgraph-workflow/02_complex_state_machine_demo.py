"""
å¤æ‚çŠ¶æ€æœºè®¾è®¡æ¼”ç¤º
å±•ç¤º LangGraph ä¸­çš„å¤æ‚çŠ¶æ€ç®¡ç†å’Œå·¥ä½œæµç¼–æ’
"""

from typing import Dict, List, Any, Optional, TypedDict
from enum import Enum
from datetime import datetime
import json


class WorkflowState(TypedDict):
    """å·¥ä½œæµçŠ¶æ€å®šä¹‰"""
    current_step: str
    input_data: Dict[str, Any]
    intermediate_results: Dict[str, Any]
    error_info: Optional[Dict[str, Any]]
    retry_count: int
    max_retries: int
    execution_history: List[Dict[str, Any]]
    final_output: Optional[Dict[str, Any]]


class WorkflowStep(Enum):
    """å·¥ä½œæµæ­¥éª¤æšä¸¾"""
    INITIALIZE = "initialize"
    DATA_PROCESSING = "data_processing"
    MODEL_INFERENCE = "model_inference"
    RESULT_VALIDATION = "result_validation"
    ERROR_HANDLING = "error_handling"
    FINALIZE = "finalize"


class WorkflowStatus(Enum):
    """å·¥ä½œæµçŠ¶æ€æšä¸¾"""
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    RETRYING = "retrying"


class ComplexStateMachine:
    """å¤æ‚çŠ¶æ€æœºç®¡ç†å™¨"""
    
    def __init__(self, max_retries: int = 3):
        self.max_retries = max_retries
        self.workflows: Dict[str, WorkflowState] = {}
    
    def initialize_workflow(self, workflow_id: str, input_data: Dict[str, Any]) -> WorkflowState:
        """åˆå§‹åŒ–å·¥ä½œæµ"""
        state: WorkflowState = {
            "current_step": WorkflowStep.INITIALIZE.value,
            "input_data": input_data,
            "intermediate_results": {},
            "error_info": None,
            "retry_count": 0,
            "max_retries": self.max_retries,
            "execution_history": [],
            "final_output": None
        }
        
        self.workflows[workflow_id] = state
        self._log_execution(workflow_id, "åˆå§‹åŒ–å·¥ä½œæµ", state)
        
        return state
    
    def execute_step(self, workflow_id: str, step: WorkflowStep) -> WorkflowState:
        """æ‰§è¡Œå·¥ä½œæµæ­¥éª¤"""
        if workflow_id not in self.workflows:
            raise ValueError(f"å·¥ä½œæµ {workflow_id} ä¸å­˜åœ¨")
        
        state = self.workflows[workflow_id]
        state["current_step"] = step.value
        
        try:
            if step == WorkflowStep.INITIALIZE:
                state = self._initialize_step(workflow_id, state)
            elif step == WorkflowStep.DATA_PROCESSING:
                state = self._data_processing_step(workflow_id, state)
            elif step == WorkflowStep.MODEL_INFERENCE:
                state = self._model_inference_step(workflow_id, state)
            elif step == WorkflowStep.RESULT_VALIDATION:
                state = self._result_validation_step(workflow_id, state)
            elif step == WorkflowStep.ERROR_HANDLING:
                state = self._error_handling_step(workflow_id, state)
            elif step == WorkflowStep.FINALIZE:
                state = self._finalize_step(workflow_id, state)
            
            # é‡ç½®é”™è¯¯ä¿¡æ¯
            state["error_info"] = None
            
        except Exception as e:
            state["error_info"] = {
                "step": step.value,
                "error_type": type(e).__name__,
                "error_message": str(e),
                "timestamp": datetime.now().isoformat()
            }
            state["retry_count"] += 1
            
            if state["retry_count"] <= state["max_retries"]:
                state["current_step"] = WorkflowStep.ERROR_HANDLING.value
                self._log_execution(workflow_id, f"æ­¥éª¤ {step.value} å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•", state)
            else:
                state["current_step"] = WorkflowStep.FINALIZE.value
                self._log_execution(workflow_id, f"æ­¥éª¤ {step.value} å¤±è´¥ï¼Œè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°", state)
        
        self.workflows[workflow_id] = state
        return state
    
    def _initialize_step(self, workflow_id: str, state: WorkflowState) -> WorkflowState:
        """åˆå§‹åŒ–æ­¥éª¤"""
        print(f"ğŸ”„ [{workflow_id}] åˆå§‹åŒ–å·¥ä½œæµ...")
        
        # éªŒè¯è¾“å…¥æ•°æ®
        input_data = state["input_data"]
        required_fields = ["query", "model_type", "max_tokens"]
        
        for field in required_fields:
            if field not in input_data:
                raise ValueError(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
        
        # è®¾ç½®åˆå§‹ä¸­é—´ç»“æœ
        state["intermediate_results"]["start_time"] = datetime.now().isoformat()
        state["intermediate_results"]["query_type"] = self._classify_query(input_data["query"])
        
        self._log_execution(workflow_id, "åˆå§‹åŒ–å®Œæˆ", state)
        return state
    
    def _data_processing_step(self, workflow_id: str, state: WorkflowState) -> WorkflowState:
        """æ•°æ®å¤„ç†æ­¥éª¤"""
        print(f"ğŸ”„ [{workflow_id}] å¤„ç†è¾“å…¥æ•°æ®...")
        
        input_data = state["input_data"]
        query = input_data["query"]
        
        # æ•°æ®é¢„å¤„ç†
        processed_data = {
            "cleaned_query": query.strip().lower(),
            "query_length": len(query),
            "word_count": len(query.split()),
            "has_special_chars": any(c in query for c in "!@#$%^&*()"),
            "processing_time": datetime.now().isoformat()
        }
        
        state["intermediate_results"]["processed_data"] = processed_data
        
        # æ¨¡æ‹Ÿæ•°æ®éªŒè¯
        if len(query) < 3:
            raise ValueError("æŸ¥è¯¢å¤ªçŸ­ï¼Œè¯·æä¾›æ›´è¯¦ç»†çš„é—®é¢˜")
        
        self._log_execution(workflow_id, "æ•°æ®å¤„ç†å®Œæˆ", state)
        return state
    
    def _model_inference_step(self, workflow_id: str, state: WorkflowState) -> WorkflowState:
        """æ¨¡å‹æ¨ç†æ­¥éª¤"""
        print(f"ğŸ”„ [{workflow_id}] æ‰§è¡Œæ¨¡å‹æ¨ç†...")
        
        input_data = state["input_data"]
        processed_data = state["intermediate_results"]["processed_data"]
        
        # æ¨¡æ‹Ÿæ¨¡å‹æ¨ç†
        model_type = input_data["model_type"]
        query = processed_data["cleaned_query"]
        
        # æ ¹æ®æŸ¥è¯¢ç±»å‹ç”Ÿæˆä¸åŒå“åº”
        query_type = state["intermediate_results"]["query_type"]
        
        if query_type == "factual":
            response = f"å…³äº '{query}' çš„äº‹å®ä¿¡æ¯ï¼šè¿™æ˜¯ä¸€ä¸ªåŸºäºäº‹å®çš„æŸ¥è¯¢ï¼Œéœ€è¦å‡†ç¡®çš„ä¿¡æ¯æ£€ç´¢ã€‚"
        elif query_type == "creative":
            response = f"å…³äº '{query}' çš„åˆ›æ„å›ç­”ï¼šè¿™æ˜¯ä¸€ä¸ªéœ€è¦åˆ›é€ åŠ›çš„æŸ¥è¯¢ï¼Œå¯ä»¥ç”Ÿæˆå¯Œæœ‰æƒ³è±¡åŠ›çš„å†…å®¹ã€‚"
        else:
            response = f"å…³äº '{query}' çš„å›ç­”ï¼šè¿™æ˜¯ä¸€ä¸ªå¸¸è§„æŸ¥è¯¢ï¼Œæä¾›æ ‡å‡†åŒ–çš„å“åº”ã€‚"
        
        inference_result = {
            "model_type": model_type,
            "response": response,
            "confidence_score": 0.85,
            "inference_time": datetime.now().isoformat(),
            "tokens_used": len(response.split()),
            "query_type": query_type
        }
        
        state["intermediate_results"]["inference_result"] = inference_result
        
        self._log_execution(workflow_id, "æ¨¡å‹æ¨ç†å®Œæˆ", state)
        return state
    
    def _result_validation_step(self, workflow_id: str, state: WorkflowState) -> WorkflowState:
        """ç»“æœéªŒè¯æ­¥éª¤"""
        print(f"ğŸ”„ [{workflow_id}] éªŒè¯æ¨ç†ç»“æœ...")
        
        inference_result = state["intermediate_results"]["inference_result"]
        
        # éªŒè¯ç»“æœè´¨é‡
        validation_checks = {
            "response_not_empty": len(inference_result["response"].strip()) > 0,
            "confidence_threshold": inference_result["confidence_score"] > 0.5,
            "reasonable_length": 10 <= inference_result["tokens_used"] <= 500,
            "no_sensitive_content": not any(word in inference_result["response"].lower() 
                                          for word in ["å¯†ç ", "å¯†é’¥", "token"])
        }
        
        failed_checks = [check for check, passed in validation_checks.items() if not passed]
        
        if failed_checks:
            raise ValueError(f"éªŒè¯å¤±è´¥: {failed_checks}")
        
        validation_result = {
            "passed_checks": len([check for check in validation_checks.values() if check]),
            "total_checks": len(validation_checks),
            "validation_time": datetime.now().isoformat(),
            "quality_score": sum([0.25 for check in validation_checks.values() if check])
        }
        
        state["intermediate_results"]["validation_result"] = validation_result
        
        self._log_execution(workflow_id, "ç»“æœéªŒè¯å®Œæˆ", state)
        return state
    
    def _error_handling_step(self, workflow_id: str, state: WorkflowState) -> WorkflowState:
        """é”™è¯¯å¤„ç†æ­¥éª¤"""
        print(f"ğŸ”„ [{workflow_id}] å¤„ç†é”™è¯¯...")
        
        error_info = state["error_info"]
        
        if error_info:
            print(f"   é”™è¯¯ç±»å‹: {error_info['error_type']}")
            print(f"   é”™è¯¯ä¿¡æ¯: {error_info['error_message']}")
            
            # æ ¹æ®é”™è¯¯ç±»å‹å†³å®šä¸‹ä¸€æ­¥
            if "éªŒè¯" in error_info["error_message"]:
                # éªŒè¯é”™è¯¯ï¼Œè¿”å›æ•°æ®é¢„å¤„ç†æ­¥éª¤
                state["current_step"] = WorkflowStep.DATA_PROCESSING.value
            elif "åˆå§‹åŒ–" in error_info["error_message"]:
                # åˆå§‹åŒ–é”™è¯¯ï¼Œéœ€è¦é‡æ–°å¼€å§‹
                state["current_step"] = WorkflowStep.INITIALIZE.value
            else:
                # å…¶ä»–é”™è¯¯ï¼Œå°è¯•æ¨¡å‹æ¨ç†æ­¥éª¤
                state["current_step"] = WorkflowStep.MODEL_INFERENCE.value
        
        self._log_execution(workflow_id, "é”™è¯¯å¤„ç†å®Œæˆ", state)
        return state
    
    def _finalize_step(self, workflow_id: str, state: WorkflowState) -> WorkflowState:
        """å®Œæˆæ­¥éª¤"""
        print(f"ğŸ”„ [{workflow_id}] å®Œæˆå·¥ä½œæµ...")
        
        if state["error_info"]:
            # å·¥ä½œæµå¤±è´¥
            state["final_output"] = {
                "status": WorkflowStatus.FAILED.value,
                "error": state["error_info"],
                "execution_time": datetime.now().isoformat()
            }
        else:
            # å·¥ä½œæµæˆåŠŸ
            inference_result = state["intermediate_results"]["inference_result"]
            validation_result = state["intermediate_results"]["validation_result"]
            
            state["final_output"] = {
                "status": WorkflowStatus.COMPLETED.value,
                "response": inference_result["response"],
                "confidence": inference_result["confidence_score"],
                "quality_score": validation_result["quality_score"],
                "execution_time": datetime.now().isoformat(),
                "total_steps": len(state["execution_history"])
            }
        
        self._log_execution(workflow_id, "å·¥ä½œæµå®Œæˆ", state)
        return state
    
    def _classify_query(self, query: str) -> str:
        """åˆ†ç±»æŸ¥è¯¢ç±»å‹"""
        factual_keywords = ["ä»€ä¹ˆ", "å¦‚ä½•", "ä¸ºä»€ä¹ˆ", "ä½•æ—¶", "å“ªé‡Œ"]
        creative_keywords = ["æƒ³è±¡", "åˆ›ä½œ", "æ•…äº‹", "è¯—æ­Œ", "åˆ›æ„"]
        
        if any(keyword in query for keyword in factual_keywords):
            return "factual"
        elif any(keyword in query for keyword in creative_keywords):
            return "creative"
        else:
            return "general"
    
    def _log_execution(self, workflow_id: str, action: str, state: WorkflowState):
        """è®°å½•æ‰§è¡Œå†å²"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "action": action,
            "step": state["current_step"],
            "retry_count": state["retry_count"]
        }
        
        state["execution_history"].append(log_entry)
    
    def get_workflow_status(self, workflow_id: str) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        if workflow_id not in self.workflows:
            return {"error": "å·¥ä½œæµä¸å­˜åœ¨"}
        
        state = self.workflows[workflow_id]
        
        return {
            "workflow_id": workflow_id,
            "current_step": state["current_step"],
            "retry_count": state["retry_count"],
            "max_retries": state["max_retries"],
            "has_error": state["error_info"] is not None,
            "is_completed": state["final_output"] is not None,
            "execution_steps": len(state["execution_history"]),
            "final_output": state["final_output"]
        }


def demo_complex_state_machine():
    """æ¼”ç¤ºå¤æ‚çŠ¶æ€æœº"""
    print("ğŸš€ å¯åŠ¨å¤æ‚çŠ¶æ€æœºæ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºçŠ¶æ€æœºå®ä¾‹
    state_machine = ComplexStateMachine(max_retries=2)
    
    # æµ‹è¯•ç”¨ä¾‹1: æ­£å¸¸æµç¨‹
    print("\nğŸ“‹ æµ‹è¯•ç”¨ä¾‹1: æ­£å¸¸å·¥ä½œæµ")
    workflow_id = "test_normal_001"
    
    input_data = {
        "query": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        "model_type": "gpt-4",
        "max_tokens": 1000
    }
    
    # åˆå§‹åŒ–å·¥ä½œæµ
    state_machine.initialize_workflow(workflow_id, input_data)
    
    # æ‰§è¡Œå®Œæ•´æµç¨‹
    steps = [
        WorkflowStep.DATA_PROCESSING,
        WorkflowStep.MODEL_INFERENCE,
        WorkflowStep.RESULT_VALIDATION,
        WorkflowStep.FINALIZE
    ]
    
    for step in steps:
        state = state_machine.execute_step(workflow_id, step)
        print(f"   æ‰§è¡Œæ­¥éª¤: {step.value}")
        print(f"   å½“å‰çŠ¶æ€: {state['current_step']}")
    
    # æŸ¥çœ‹æœ€ç»ˆç»“æœ
    status = state_machine.get_workflow_status(workflow_id)
    print(f"\nâœ… å·¥ä½œæµå®Œæˆ:")
    print(f"   çŠ¶æ€: {status['final_output']['status']}")
    print(f"   å“åº”: {status['final_output']['response']}")
    print(f"   ç½®ä¿¡åº¦: {status['final_output']['confidence']}")
    print(f"   è´¨é‡åˆ†æ•°: {status['final_output']['quality_score']}")
    
    # æµ‹è¯•ç”¨ä¾‹2: å¸¦é”™è¯¯çš„é‡è¯•æµç¨‹
    print("\nğŸ“‹ æµ‹è¯•ç”¨ä¾‹2: å¸¦é”™è¯¯çš„é‡è¯•æµç¨‹")
    workflow_id2 = "test_error_002"
    
    input_data2 = {
        "query": "AI",  # å¤ªçŸ­çš„æŸ¥è¯¢ä¼šè§¦å‘éªŒè¯é”™è¯¯
        "model_type": "gpt-4",
        "max_tokens": 1000
    }
    
    state_machine.initialize_workflow(workflow_id2, input_data2)
    
    # æ‰§è¡Œæµç¨‹ï¼ˆä¼šè§¦å‘é”™è¯¯å’Œé‡è¯•ï¼‰
    steps2 = [
        WorkflowStep.DATA_PROCESSING,  # è¿™é‡Œä¼šè§¦å‘éªŒè¯é”™è¯¯
        WorkflowStep.ERROR_HANDLING,   # é”™è¯¯å¤„ç†
        WorkflowStep.DATA_PROCESSING,  # é‡è¯•æ•°æ®å¤„ç†
        WorkflowStep.MODEL_INFERENCE,
        WorkflowStep.RESULT_VALIDATION,
        WorkflowStep.FINALIZE
    ]
    
    for step in steps2:
        state = state_machine.execute_step(workflow_id2, step)
        print(f"   æ‰§è¡Œæ­¥éª¤: {step.value}")
        print(f"   å½“å‰çŠ¶æ€: {state['current_step']}")
        if state['error_info']:
            print(f"   é”™è¯¯ä¿¡æ¯: {state['error_info']['error_message']}")
    
    # æŸ¥çœ‹æœ€ç»ˆç»“æœ
    status2 = state_machine.get_workflow_status(workflow_id2)
    print(f"\nğŸ”„ å·¥ä½œæµå®Œæˆï¼ˆå¸¦é‡è¯•ï¼‰:")
    print(f"   çŠ¶æ€: {status2['final_output']['status']}")
    print(f"   é‡è¯•æ¬¡æ•°: {status2['retry_count']}")
    print(f"   æ‰§è¡Œæ­¥éª¤æ•°: {status2['execution_steps']}")
    
    # æµ‹è¯•ç”¨ä¾‹3: åˆ†å¸ƒå¼å·¥ä½œæµç¼–æ’æ¼”ç¤º
    print("\nğŸ“‹ æµ‹è¯•ç”¨ä¾‹3: åˆ†å¸ƒå¼å·¥ä½œæµç¼–æ’")
    workflow_ids = ["distributed_001", "distributed_002", "distributed_003"]
    
    queries = [
        "æœºå™¨å­¦ä¹ çš„åŸºæœ¬åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
        "åˆ›ä½œä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—æ­Œ",
        "æ·±åº¦å­¦ä¹ åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨"
    ]
    
    print("   å¯åŠ¨åˆ†å¸ƒå¼å·¥ä½œæµæ‰§è¡Œ...")
    
    # å¹¶è¡Œåˆå§‹åŒ–å¤šä¸ªå·¥ä½œæµ
    for i, (wf_id, query) in enumerate(zip(workflow_ids, queries)):
        input_data = {
            "query": query,
            "model_type": "gpt-4",
            "max_tokens": 500
        }
        state_machine.initialize_workflow(wf_id, input_data)
        print(f"   å·¥ä½œæµ {wf_id} å·²åˆå§‹åŒ–")
    
    # å¹¶è¡Œæ‰§è¡Œæ•°æ®å¤„ç†æ­¥éª¤
    print("\n   å¹¶è¡Œæ‰§è¡Œæ•°æ®å¤„ç†æ­¥éª¤...")
    for wf_id in workflow_ids:
        state_machine.execute_step(wf_id, WorkflowStep.DATA_PROCESSING)
        print(f"   å·¥ä½œæµ {wf_id} æ•°æ®å¤„ç†å®Œæˆ")
    
    # å¹¶è¡Œæ‰§è¡Œæ¨¡å‹æ¨ç†æ­¥éª¤
    print("\n   å¹¶è¡Œæ‰§è¡Œæ¨¡å‹æ¨ç†æ­¥éª¤...")
    for wf_id in workflow_ids:
        state_machine.execute_step(wf_id, WorkflowStep.MODEL_INFERENCE)
        print(f"   å·¥ä½œæµ {wf_id} æ¨¡å‹æ¨ç†å®Œæˆ")
    
    # å®Œæˆæ‰€æœ‰å·¥ä½œæµ
    print("\n   å®Œæˆæ‰€æœ‰å·¥ä½œæµ...")
    for wf_id in workflow_ids:
        state_machine.execute_step(wf_id, WorkflowStep.RESULT_VALIDATION)
        state_machine.execute_step(wf_id, WorkflowStep.FINALIZE)
        
        status = state_machine.get_workflow_status(wf_id)
        print(f"   å·¥ä½œæµ {wf_id}: {status['final_output']['status']}")
    
    print("\n" + "=" * 50)
    print("ğŸ‰ å¤æ‚çŠ¶æ€æœºæ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ“Š æ¼”ç¤ºæ€»ç»“:")
    print("   â€¢ æ­£å¸¸æµç¨‹æ‰§è¡Œ: å±•ç¤ºäº†å®Œæ•´çš„å·¥ä½œæµæ‰§è¡Œ")
    print("   â€¢ é”™è¯¯å¤„ç†ä¸é‡è¯•: æ¼”ç¤ºäº†é”™è¯¯æ£€æµ‹å’Œè‡ªåŠ¨é‡è¯•æœºåˆ¶")
    print("   â€¢ åˆ†å¸ƒå¼ç¼–æ’: å±•ç¤ºäº†å¹¶è¡Œå·¥ä½œæµæ‰§è¡Œèƒ½åŠ›")
    print("   â€¢ çŠ¶æ€ç®¡ç†: å®ç°äº†å¤æ‚çš„çŠ¶æ€è·Ÿè¸ªå’Œè½¬æ¢")


if __name__ == "__main__":
    demo_complex_state_machine()